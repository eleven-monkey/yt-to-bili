# -*- coding: utf-8 -*-
import os
import re
import json
import time
import shutil
import subprocess
import asyncio
import glob
import random
import threading
from datetime import datetime
from pathlib import Path
import tempfile
import zipfile
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from PIL import Image

import streamlit as st
import yt_dlp
import requests
import edge_tts
from bilibili_api import sync, video_uploader, Credential
from bilibili_api.video_uploader import VideoUploaderPage, VideoMeta
import pydub
import pickle
from worker_utils import process_segment, adjust_audio_speed

def load_env_config():
    """
    åŠ è½½é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡(HuggingFace Secrets)ï¼Œå…¶æ¬¡ä½¿ç”¨.envæ–‡ä»¶
    """
    config = {}
    
    # 1. å…ˆåŠ è½½ .env æ–‡ä»¶ (å¦‚æœæœ‰)
    env_file = os.path.join(os.getcwd(), ".env")
    if os.path.exists(env_file):
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        config[key.strip()] = value.strip()
        except Exception as e:
            print(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")

    # 2. å†åŠ è½½ç³»ç»Ÿç¯å¢ƒå˜é‡ (è¦†ç›– .env ä¸­çš„åŒåé…ç½®)
    # æˆ‘ä»¬å…³å¿ƒçš„ç‰¹å®šç¯å¢ƒå˜é‡åˆ—è¡¨
    target_keys = [
        "API_KEY", "API_URL", "MODEL_NAME", 
        "YT_COOKIES", 
        "BILI_SESSDATA", "BILI_BILI_JCT", "BILI_BUVID3", 
        "BILI_ACCESS_KEY_ID", "BILI_ACCESS_KEY_SECRET"
    ]
    
    for key in target_keys:
        env_val = os.getenv(key)
        if env_val:
            if key == "YT_COOKIES":
                env_val = env_val.replace("\\n", "\n")
            config[key] = env_val
            
    # å…¼å®¹æ—§çš„/æ‹¼å†™é”™è¯¯çš„å˜é‡å BILI_SESSIDATA -> BILI_SESSDATA
    if "BILI_SESSDATA" not in config and os.getenv("BILI_SESSIDATA"):
        config["BILI_SESSDATA"] = os.getenv("BILI_SESSIDATA")
            
    return config

env_config = load_env_config()

# --- çŠ¶æ€ç®¡ç†ä¸åå°ä»»åŠ¡ç›¸å…³ ---
STATUS_FILE = "workflow_status.json"

class WorkflowManager:
    @staticmethod
    def get_status_file_path(temp_dir):
        return os.path.join(temp_dir, STATUS_FILE)

    @staticmethod
    def init_status(temp_dir):
        status = {
            "is_running": True,
            "start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "steps": {
                "ä¸‹è½½å­—å¹•": {"status": "pending", "message": ""},
                "ç¿»è¯‘æ ‡é¢˜": {"status": "pending", "message": ""},
                "ç¿»è¯‘å­—å¹•": {"status": "pending", "message": ""},
                "è½¬è¯­éŸ³": {"status": "pending", "message": ""},
                "ä¸‹è½½è§†é¢‘": {"status": "pending", "message": ""},
                "å¤„ç†å°é¢": {"status": "pending", "message": ""},
                "ä¸Šä¼ Bç«™": {"status": "pending", "message": ""}
            },
            "results": {},
            "error": None,
            "logs": []
        }
        WorkflowManager.save_status(temp_dir, status)
        return status

    @staticmethod
    def load_status(temp_dir):
        file_path = WorkflowManager.get_status_file_path(temp_dir)
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return None
        return None

    @staticmethod
    def save_status(temp_dir, status):
        file_path = WorkflowManager.get_status_file_path(temp_dir)
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")

    @staticmethod
    def update_step(temp_dir, step_name, status_code, message=""):
        """
        status_code: pending, running, success, error
        """
        current_status = WorkflowManager.load_status(temp_dir)
        if current_status:
            if step_name in current_status["steps"]:
                current_status["steps"][step_name]["status"] = status_code
                current_status["steps"][step_name]["message"] = message
            current_status["logs"].append(f"[{datetime.now().strftime('%H:%M:%S')}] {step_name}: {status_code} - {message}")
            WorkflowManager.save_status(temp_dir, current_status)

    @staticmethod
    def mark_completed(temp_dir, results=None):
        current_status = WorkflowManager.load_status(temp_dir)
        if current_status:
            current_status["is_running"] = False
            if results:
                current_status["results"].update(results)
            WorkflowManager.save_status(temp_dir, current_status)

    @staticmethod
    def mark_error(temp_dir, error_msg):
        current_status = WorkflowManager.load_status(temp_dir)
        if current_status:
            current_status["is_running"] = False
            current_status["error"] = error_msg
            WorkflowManager.save_status(temp_dir, current_status)

def background_workflow_task(config):
    """
    åå°è¿è¡Œçš„å·¥ä½œæµä¸»å‡½æ•°
    config: åŒ…å«æ‰€æœ‰å¿…è¦å‚æ•°çš„å­—å…¸
    """
    temp_dir = config['temp_dir']
    workflow_url = config['workflow_url']
    auto_upload = config['auto_upload']
    
    # åˆå§‹åŒ–çŠ¶æ€
    WorkflowManager.init_status(temp_dir)
    
    try:
        subtitles_dir = os.path.join(temp_dir, "subtitles")
        os.makedirs(subtitles_dir, exist_ok=True)
        
        # --- æ­¥éª¤1: ä¸‹è½½å­—å¹• ---
        WorkflowManager.update_step(temp_dir, "ä¸‹è½½å­—å¹•", "running", "æ­£åœ¨ä¸‹è½½å­—å¹•...")
        
        cookies_file_path = None
        if config.get('yt_cookies', '').strip():
            cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                f.write(config['yt_cookies'].strip())
        
        ydl_opts = {
            'writeautomaticsub': True,
            'skip_download': True,
            'subtitleslangs': ['en'],
            'quiet': True,
            'outtmpl': os.path.join(subtitles_dir, '%(title)s.%(ext)s'),
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
        }
        
        if cookies_file_path:
            ydl_opts['cookiefile'] = cookies_file_path
        
        # é‡è¯•æœºåˆ¶
        def retry_op(func, max_retries=3):
            for attempt in range(max_retries):
                try:
                    return func()
                except Exception as e:
                    if attempt == max_retries - 1: raise e
                    time.sleep(2 ** attempt)

        def dl_sub():
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([workflow_url])
            vtt_files = list(Path(subtitles_dir).glob("*.vtt"))
            if not vtt_files: raise Exception("æœªæ‰¾åˆ°VTTæ–‡ä»¶")
            original_file = vtt_files[0]
            new_file = os.path.join(subtitles_dir, "word_level.vtt")
            # å¦‚æœå­˜åœ¨åˆ™è¦†ç›–
            if os.path.exists(new_file): os.remove(new_file)
            os.rename(original_file, new_file)
            return new_file

        vtt_file_path = retry_op(dl_sub)
        WorkflowManager.update_step(temp_dir, "ä¸‹è½½å­—å¹•", "success", f"å·²ä¿å­˜: {os.path.basename(vtt_file_path)}")
        
        # --- æ­¥éª¤2: ç¿»è¯‘æ ‡é¢˜ ---
        WorkflowManager.update_step(temp_dir, "ç¿»è¯‘æ ‡é¢˜", "running", "æ­£åœ¨åˆ†æè§†é¢‘ä¿¡æ¯...")
        
        def trans_title():
            ydl_info_opts = {
                'skip_download': True, 
                'quiet': True,
                'http_headers': {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }
            }
            if cookies_file_path: ydl_info_opts['cookiefile'] = cookies_file_path
            
            with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
                info_dict = ydl.extract_info(workflow_url, download=False)
                original_title = info_dict.get('title', '')
            
            if not original_title: raise Exception("æ— æ³•è·å–æ ‡é¢˜")
            
            # è°ƒç”¨APIç¿»è¯‘
            headers = {"Authorization": f"Bearer {config['api_key']}", "Content-Type": "application/json"}
            
            # æ ‡é¢˜ç¿»è¯‘
            payload = {
                "model": config['model_name'],
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯çˆ†æ¬¾è§†é¢‘upä¸»ï¼Œå°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆå¸å¼•çœ¼çƒçš„çˆ†æ¬¾è§†é¢‘ä¸­æ–‡æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"},
                    {"role": "user", "content": original_title}
                ]
            }
            resp = requests.post(config['api_url'], json=payload, headers=headers, timeout=60)
            translated_title = resp.json()['choices'][0]['message']['content'].replace('**', '').strip()
            
            # æ ‡ç­¾ç”Ÿæˆ
            tags_payload = {
                "model": config['model_name'],
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Bç«™è¿è¥åŠ©æ‰‹"},
                    {"role": "user", "content": f"æ ¹æ®ä»¥ä¸‹è§†é¢‘æ ‡é¢˜ï¼Œç”Ÿæˆ5-8ä¸ªBç«™è§†é¢‘æ ‡ç­¾ï¼ˆåªè¾“å‡ºæ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼‰ï¼š\næ ‡é¢˜ï¼š{translated_title}\nåªè¾“å‡ºæ ‡ç­¾ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"}
                ]
            }
            tags_resp = requests.post(config['api_url'], json=tags_payload, headers=headers, timeout=60)
            tags_str = tags_resp.json()['choices'][0]['message']['content']
            tags_list = [t.strip() for t in tags_str.replace('ï¼Œ', ',').split(',') if t.strip()][:10]
            
            # ä¿å­˜ä¸Šä¼ é…ç½®
            upload_data = {'title_desc': f'(ä¸­é…){translated_title}', 'tags': tags_list}
            with open(os.path.join(subtitles_dir, "upload_config.pkl"), 'wb') as f:
                pickle.dump(upload_data, f)
                
            return translated_title, tags_list
            
        translated_title, tags_list = retry_op(trans_title)
        WorkflowManager.update_step(temp_dir, "ç¿»è¯‘æ ‡é¢˜", "success", f"æ ‡é¢˜: {translated_title}")
        
        # --- æ­¥éª¤3: ç¿»è¯‘å­—å¹• ---
        WorkflowManager.update_step(temp_dir, "ç¿»è¯‘å­—å¹•", "running", "AIæ­£åœ¨ç¿»è¯‘ä¸­(å¯èƒ½è¾ƒæ…¢)...")
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨å…¨å±€å‡½æ•°ï¼Œå®ƒä¼šæ‰“å°æ—¥å¿—åˆ°stdoutï¼Œä½†æˆ‘ä»¬éœ€è¦å®ƒæ­£å¸¸è¿è¡Œ
        # æˆ‘ä»¬å¯ä»¥æš‚æ—¶ä¸æ•è·å®ƒçš„è¯¦ç»†è¿›åº¦ï¼Œæˆ–è€…ä¿®æ”¹åŸå‡½æ•°ã€‚ä¸ºä¿æŒæœ€å°æ”¹åŠ¨ï¼Œç›´æ¥è°ƒç”¨ã€‚
        # è¿™é‡Œçš„å…¨å±€å˜é‡ API_URL, API_KEY ç­‰éœ€è¦åœ¨è°ƒç”¨å‰ä¸´æ—¶è¦†ç›–å—ï¼Ÿ
        # å…¨å±€å‡½æ•° translate_subtitles_from_vtt ä½¿ç”¨äº†å…¨å±€å˜é‡ API_URL ç­‰ã€‚
        # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ä¿®æ”¹å…¨å±€å˜é‡æ˜¯å±é™©çš„ã€‚
        # ä½†è¿™é‡Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ python çš„åŠ¨æ€æ€§ï¼Œæˆ–è€…å‡è®¾ config ä¸­çš„å€¼å’Œå…¨å±€çš„ä¸€è‡´ã€‚
        # å®é™…ä¸Š app.py é‡Œçš„ API_URL æ˜¯ä» st.sidebar è·å–çš„ï¼Œåœ¨åå°çº¿ç¨‹é‡Œæ— æ³•è®¿é—® st.sidebarã€‚
        # å¿…é¡»ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®ï¼Œæˆ–è€…é‡æ„ translate_subtitles_from_vtt æ¥å—å‚æ•°ã€‚
        # ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬è¿™é‡Œåšä¸€ä¸ªç®€å•çš„ trickï¼šåœ¨ app.py é¡¶å±‚ï¼ŒAPI_URL ç­‰æ˜¯å…¨å±€å˜é‡ã€‚
        # ç”¨æˆ·åœ¨ UI ä¿®æ”¹åï¼Œè¿™äº›å…¨å±€å˜é‡å¹¶æ²¡æœ‰å˜ï¼ˆå®ƒä»¬åªæ˜¯è„šæœ¬é¡¶å±‚çš„åˆå§‹å€¼ï¼‰ã€‚
        # st.sidebar çš„å€¼æ˜¯åœ¨ st è¿è¡Œæ—¶è·å–çš„ã€‚
        # è¿™æ˜¯ä¸€ä¸ªæ½œåœ¨ BUGï¼šåŸä»£ç ä¸­ translate_subtitles_from_vtt ç›´æ¥ç”¨äº† API_URLã€‚
        # åœ¨ Streamlit ä¸­ï¼Œæ¯æ¬¡ rerun æ•´ä¸ªè„šæœ¬ä»å¤´è·‘ï¼Œå…¨å±€å˜é‡é‡ç½®ã€‚
        # å½“ç‚¹å‡»æŒ‰é’®æ—¶ï¼ŒAPI_URL æ˜¯å½“å‰å±€éƒ¨å˜é‡ï¼ˆå¦‚æœæ˜¯é€šè¿‡ st.sidebar... è¿”å›çš„ï¼‰ã€‚
        # åŸä»£ç ä¸­ï¼šAPI_URL = st.sidebar.text_input(...)
        # æ‰€ä»¥ API_URL åœ¨è„šæœ¬æ‰§è¡ŒåŸŸä¸­æ˜¯å­˜åœ¨çš„ã€‚
        # ä½†æ˜¯ï¼Œå½“çº¿ç¨‹è¿è¡Œæ—¶ï¼Œå¦‚æœä¸»çº¿ç¨‹ï¼ˆStreamlit runnerï¼‰ç»“æŸæˆ– rerunï¼Œè¿™äº›æ¨¡å—çº§å˜é‡è¿˜åœ¨å—ï¼Ÿ
        # åœ¨ Streamlit ä¸­ï¼Œæ¨¡å—çº§åˆ«çš„å˜é‡æ˜¯è·¨ session å…±äº«çš„ï¼ˆå¦‚æœä¸æ˜¯åœ¨å‡½æ•°å†…å®šä¹‰ï¼‰ã€‚
        # ä½† API_URL = st.sidebar... æ˜¯åœ¨è„šæœ¬æ‰§è¡Œæµä¸­å®šä¹‰çš„ã€‚
        # ä¸ºäº†ç¡®ä¿åå°çº¿ç¨‹èƒ½æ‹¿åˆ°æ­£ç¡®çš„é…ç½®ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ translate_subtitles_from_vtt 
        # æˆ–è€…ä¸´æ—¶è®¾ç½®å…¨å±€å˜é‡ï¼ˆä¸æ¨èï¼‰ã€‚
        # æœ€ç¨³å¦¥çš„æ–¹æ³•ï¼šä¿®æ”¹ translate_subtitles_from_vtt ç­¾åæ¥å— api_key ç­‰å‚æ•°ã€‚
        # ä½†ç”¨æˆ·è¦æ±‚ "ä¸è¦ç€æ€¥ç¼–ç " ä¸” "mimic style"ï¼Œæˆ‘é€‰æ‹©ä¸€ç§ä¾µå…¥æ€§å°çš„æ–¹æ³•ï¼š
        # å°†é…ç½®æ³¨å…¥åˆ°å…¨å±€ï¼ˆè™½ç„¶æœ‰ç‚¹è„ï¼Œä½†åœ¨å•å®ä¾‹å®¹å™¨ä¸­å¯è¡Œï¼‰ï¼Œæˆ–è€…æœ€å¥½ç¨å¾®ä¿®æ”¹ä¸€ä¸‹ translate_subtitles_from_vttã€‚
        # è®©æˆ‘ä»¬çœ‹çœ‹ translate_subtitles_from_vtt å®šä¹‰ã€‚å®ƒç¡®å®ä½¿ç”¨äº†å…¨å±€ API_URLã€‚
        # æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ unittest.mock.patch æˆ–è€…ç®€å•çš„ global èµ‹å€¼æ¥ç¡®ä¿çº¿ç¨‹å†…çœ‹åˆ°çš„å˜é‡æ˜¯å¯¹çš„ã€‚
        # ä½†ç”±äºè¿™æ˜¯å¤šçº¿ç¨‹ï¼Œä¿®æ”¹å…¨å±€å˜é‡ä¼šå½±å“å…¶ä»–ç”¨æˆ·ï¼ˆè™½ç„¶ streamlit é€šå¸¸å•å®ä¾‹ï¼‰ã€‚
        # æ›´å¥½çš„æ–¹æ¡ˆï¼šä¼ é€’å‚æ•°ã€‚
        # æˆ‘å°†ä¿®æ”¹ translate_subtitles_from_vtt åŠå…¶è°ƒç”¨çš„å‡½æ•°ï¼Œä½†è¿™æ”¹åŠ¨å¤§ã€‚
        # è®©æˆ‘ä»¬ç”¨ global å˜é‡æ³¨å…¥çš„æ–¹å¼ï¼ˆåœ¨çº¿ç¨‹å¼€å§‹å‰ï¼Œæˆ–è€…å‡è®¾ç”¨æˆ·æ²¡æœ‰å˜ï¼‰ã€‚
        # å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥é‡å†™ translate_subtitles_from_vtt çš„éƒ¨åˆ†é€»è¾‘åœ¨çº¿ç¨‹é‡Œï¼Œæˆ–è€…ï¼Œ
        # é‰´äº `translate_subtitles_from_vtt` å°±åœ¨ `app.py` é‡Œï¼Œ
        # æˆ‘å¯ä»¥ç®€å•åœ°å°†è¿™äº›é…ç½®ä½œä¸ºå‚æ•°ä¼ é€’ç»™ `translate_subtitles_from_vtt`ï¼Œç»™å®ƒåŠ é»˜è®¤å‚æ•°=Noneï¼Œå¦‚æœNoneåˆ™å–å…¨å±€ã€‚
        # è¿™æ ·æ”¹åŠ¨æœ€å°ã€‚
        
        # ç¨åæˆ‘ä¼šå¾®è°ƒ translate_subtitles_from_vttã€‚ç°åœ¨å…ˆå‡è®¾å®ƒèƒ½å·¥ä½œï¼ˆå¦‚æœå®ƒå¼•ç”¨çš„å…¨å±€å˜é‡è¢«æ­£ç¡®é—­åŒ…æ•è·ï¼‰ã€‚
        # å®é™…ä¸Š python çš„é—­åŒ…æ˜¯è¿Ÿç»‘å®šçš„ã€‚
        # ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘åœ¨ background_workflow_task é‡Œå®šä¹‰ä¸€ä¸ª wrapper æˆ–è€… monkeypatchã€‚
        # è®©æˆ‘ä»¬å°è¯•ä¸€ç§ Pythonic çš„æ–¹æ³•ï¼šåŠ¨æ€ä¿®æ”¹å…¨å±€å˜é‡ä¸Šä¸‹æ–‡ï¼Ÿä¸ï¼Œå¤ªé»‘é­”æ³•ã€‚
        # æˆ‘å°†ä¿®æ”¹ `translate_subtitles_from_vtt` æ¥å—å¯é€‰çš„ api_config å‚æ•°ã€‚
        
        txt_file_path = translate_subtitles_from_vtt(vtt_file_path, api_config={
            "API_URL": config['api_url'],
            "API_KEY": config['api_key'],
            "MODEL_NAME": config['model_name'],
            "MAX_WORKERS": config['max_workers'],
            "SEGMENT_SIZE": config['segment_size']
        })
        
        WorkflowManager.update_step(temp_dir, "ç¿»è¯‘å­—å¹•", "success", f"å·²ä¿å­˜: {os.path.basename(txt_file_path)}")
        
        # --- æ­¥éª¤4: è½¬è¯­éŸ³ ---
        WorkflowManager.update_step(temp_dir, "è½¬è¯­éŸ³", "running", "æ­£åœ¨è¿›è¡ŒTTSè½¬æ¢...")
        
        output_mp3 = os.path.join(subtitles_dir, os.path.splitext(os.path.basename(vtt_file_path))[0] + "_translated.mp3")
        # åŒç†ï¼Œprocess_tts_with_speed_adjustment ä¹Ÿéœ€è¦ config
        mp3_file_path = process_tts_with_speed_adjustment(txt_file_path, output_mp3, subtitles_dir, tts_config={
            "TEMP_DIR": temp_dir,
            "SELECTED_VOICE": config['voice_choice']
        })
        
        if not mp3_file_path: raise Exception("TTSè½¬æ¢å¤±è´¥")
        WorkflowManager.update_step(temp_dir, "è½¬è¯­éŸ³", "success", f"å·²ç”Ÿæˆ: {os.path.basename(mp3_file_path)}")
        
        # --- æ­¥éª¤5: ä¸‹è½½è§†é¢‘ ---
        WorkflowManager.update_step(temp_dir, "ä¸‹è½½è§†é¢‘", "running", "ä¸‹è½½å¹¶åˆå¹¶è§†é¢‘...")
        
        def dl_video():
            dl_base = os.path.join(temp_dir, "subtitles", "downloaded_video")
        ydl_v_opts = {
            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
            'outtmpl': video_file,
            'quiet': True,
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
        }
            if cookies_file_path: ydl_v_opts['cookiefile'] = cookies_file_path
            
            with yt_dlp.YoutubeDL(ydl_v_opts) as ydl:
                ydl.extract_info(workflow_url, download=True)
            
            dl_files = glob.glob(f"{dl_base}.*")
            if not dl_files: raise Exception("è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")
            
            raw_video = dl_files[0]
            final_vid = os.path.splitext(mp3_file_path)[0] + ".mp4"
            
            subprocess.run(['ffmpeg', '-y', '-i', raw_video, '-i', mp3_file_path,
                           '-c:v', 'copy', '-c:a', 'aac', '-map', '0:v:0', '-map', '1:a:0',
                           final_vid], check=True, capture_output=True)
            
            if os.path.exists(raw_video): os.remove(raw_video)
            return final_vid
            
        final_video_path = retry_op(dl_video)
        WorkflowManager.update_step(temp_dir, "ä¸‹è½½è§†é¢‘", "success", f"æœ€ç»ˆè§†é¢‘: {os.path.basename(final_video_path)}")
        
        # --- æ­¥éª¤6: å¤„ç†å°é¢ ---
        WorkflowManager.update_step(temp_dir, "å¤„ç†å°é¢", "running", "ä¼˜åŒ–å°é¢å›¾ç‰‡...")
        
        def proc_cover():
        ydl_cov_opts = {
            'skip_download': True,
            'writethumbnail': True,
            'outtmpl': os.path.join(temp_dir, 'cover'),
            'quiet': True,
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
        }
            if cookies_file_path: ydl_cov_opts['cookiefile'] = cookies_file_path
            
            with yt_dlp.YoutubeDL(ydl_cov_opts) as ydl:
                ydl.extract_info(workflow_url, download=True)
            
            # å¯»æ‰¾å°é¢æ–‡ä»¶
            cover_candidates = list(Path(os.path.join(temp_dir, "subtitles")).glob("cover.*"))
            # æ’é™¤å·²ç»æ˜¯jpegçš„é˜²æ­¢é‡å¤å¤„ç†
            src_cover = None
            for c in cover_candidates:
                if c.suffix.lower() in ['.webp', '.jpg', '.png']:
                    src_cover = c
                    break
            
            if not src_cover: return "æ— å°é¢" # åº”è¯¥ä¸ä¼šå‘ç”Ÿ
            
            out_cover = os.path.join(temp_dir, "subtitles", "cover.jpeg")
            qual = 90
            with Image.open(src_cover) as img:
                if img.mode != 'RGB': img = img.convert('RGB')
                img.save(out_cover, 'jpeg', quality=qual)
                
                # å‹ç¼©åˆ°åˆé€‚å¤§å°
                while os.path.getsize(out_cover) / 1024 > 50 and qual > 10:
                    qual -= 5
                    img.save(out_cover, 'jpeg', quality=qual)
            return out_cover

        cover_path = retry_op(proc_cover)
        WorkflowManager.update_step(temp_dir, "å¤„ç†å°é¢", "success", "å°é¢å¤„ç†å®Œæˆ")
        
        results = {
            "vtt": vtt_file_path,
            "txt": txt_file_path,
            "mp3": mp3_file_path,
            "video": final_video_path,
            "cover": cover_path
        }
        
        # --- æ­¥éª¤7: ä¸Šä¼ Bç«™ ---
        if auto_upload:
            WorkflowManager.update_step(temp_dir, "ä¸Šä¼ Bç«™", "running", "æ­£åœ¨ä¸Šä¼ åˆ°Bç«™...")
            
            credential = Credential(sessdata=config['bili_sess'], bili_jct="bcd4ba0d9ab8a7b95485798ed8097d26")
            vu_meta = VideoMeta(
                tid=130, title=translated_title, tags=tags_list,
                desc=translated_title, cover=cover_path, no_reprint=True
            )
            
            async def upload_task():
                page = VideoUploaderPage(path=final_video_path, title=translated_title, description=translated_title)
                uploader = video_uploader.VideoUploader([page], vu_meta, credential, line=video_uploader.Lines.QN)
                await uploader.start()
            
            # åœ¨æ–°äº‹ä»¶å¾ªç¯è¿è¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(upload_task())
            loop.close()
            
            WorkflowManager.update_step(temp_dir, "ä¸Šä¼ Bç«™", "success", "ä¸Šä¼ æˆåŠŸï¼")
        else:
            WorkflowManager.update_step(temp_dir, "ä¸Šä¼ Bç«™", "success", "è·³è¿‡ä¸Šä¼ ")

        WorkflowManager.mark_completed(temp_dir, results)

    except Exception as e:
        import traceback
        err_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"åå°ä»»åŠ¡å‡ºé”™: {err_msg}")
        WorkflowManager.mark_error(temp_dir, str(e))

def clear_temp_directory():
    """æ¸…ç©ºtempç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹"""
    import shutil
    try:
        if os.path.exists(TEMP_DIR):
            for filename in os.listdir(TEMP_DIR):
                file_path = os.path.join(TEMP_DIR, filename)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                except Exception as e:
                    print(f'æ¸…ç©ºtempç›®å½•æ—¶å‡ºé”™ {file_path}: {e}')
            print("tempç›®å½•å·²æ¸…ç©º")
        else:
            os.makedirs(TEMP_DIR, exist_ok=True)
            print("tempç›®å½•å·²åˆ›å»º")
    except Exception as e:
        print(f"æ¸…ç©ºtempç›®å½•å¤±è´¥: {e}")

# ç¿»è¯‘å­—å¹•ç›¸å…³å‡½æ•°
def translate_subtitles_from_vtt(vtt_file_path, api_config=None):
    """ä»VTTæ–‡ä»¶ç¿»è¯‘å­—å¹•ï¼Œç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆå•æ­¥æ‰§è¡Œçš„å®Œæ•´é€»è¾‘ï¼‰"""
    # è·å–é…ç½®ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨å…¨å±€å˜é‡
    cfg_api_url = api_config.get("API_URL", API_URL) if api_config else API_URL
    cfg_api_key = api_config.get("API_KEY", API_KEY) if api_config else API_KEY
    cfg_model = api_config.get("MODEL_NAME", MODEL_NAME) if api_config else MODEL_NAME
    cfg_max_workers = api_config.get("MAX_WORKERS", MAX_WORKERS) if api_config else MAX_WORKERS
    cfg_seg_size = api_config.get("SEGMENT_SIZE", SEGMENT_SIZE) if api_config else SEGMENT_SIZE

    def vtt_to_sentences(vtt_text):
        """å°†å¸¦é€è¯æ—¶é—´æˆ³çš„VTTè½¬æ¢ä¸ºæŒ‰å¥åˆ†æ®µçš„æ–‡æœ¬"""
        # æ­£åˆ™ï¼šcue å¤´ï¼ˆèµ·æ­¢æ—¶é—´ï¼‰
        CUE_HEADER_RE = re.compile(
            r'^(\d{2}:\d{2}:\d{2}\.\d{3})\s*--> (\d{2}:\d{2}:\d{2}\.\d{3})'
        )

        # æ­£åˆ™ï¼šé€è¯æ—¶é—´æˆ³ <HH:MM:SS.mmm>
        TS_TAG_RE = re.compile(r'<(\d{2}:\d{2}:\d{2}\.\d{3})>')

        # æ­£åˆ™ï¼šæ¸…ç† <c> æˆ– <c.xxx> æ ·å¼æ ‡ç­¾
        C_TAG_RE = re.compile(r'</?c(?:\.[^>]*)?>', re.IGNORECASE)

        SENTENCE_END = ".!?"

        lines = vtt_text.splitlines()
        sentences = []
        current_words = []
        current_sentence_start_time = None

        effective_time = None
        cue_start_time = None

        def flush_sentence():
            nonlocal current_words, current_sentence_start_time
            if not current_words:
                return
            text = " ".join(current_words)
            text = re.sub(r"\s+([,.;!?])", r"\1", text)
            text = re.sub(r"\(\s+", "(", text)
            text = re.sub(r"\s+\)", ")", text)
            start_ts = current_sentence_start_time or cue_start_time or effective_time or "00:00:00.000"
            sentences.append(f"({start_ts}) {text}")
            current_words = []
            current_sentence_start_time = None

        for line in lines:
            line = line.strip("\ufeff\r\n")

            # cue å¤´
            m = CUE_HEADER_RE.match(line)
            if m:
                cue_start_time = m.group(1)
                effective_time = cue_start_time
                continue

            # åªå¤„ç†å«é€è¯æ—¶é—´æˆ³çš„è¡Œ
            if not TS_TAG_RE.search(line):
                continue

            # æ¸…ç† <c> æ ‡ç­¾ï¼Œå¹¶æŠŠ <timestamp> å˜æˆ [[TS:...]] å“¨å…µ
            s = C_TAG_RE.sub("", line)
            s = TS_TAG_RE.sub(lambda mm: f" [[TS:{mm.group(1)}]] ", s)

            # æ‰«æ token
            for token in s.split():
                if token.startswith("[[TS:") and token.endswith("]]"):
                    effective_time = token[5:-2]
                    continue

                word = token.strip()
                if not word:
                    continue

                # è®°å½•é¦–è¯æ—¶é—´
                if current_sentence_start_time is None:
                    current_sentence_start_time = effective_time or cue_start_time

                current_words.append(word)

                # å¥å­ç»“æŸåˆ¤å®šï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰
                if word.strip().endswith(tuple(SENTENCE_END)):
                    flush_sentence()

        # æ–‡ä»¶ç»“æŸï¼Œæ”¶å°¾
        flush_sentence()
        return sentences

    vtt_content = Path(vtt_file_path).read_text(encoding="utf-8", errors="ignore")
    sentences = vtt_to_sentences(vtt_content)

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šè§£æå‡º {len(sentences)} ä¸ªå¥å­")
    if sentences:
        print(f"å‰3ä¸ªå¥å­ç¤ºä¾‹ï¼š")
        for i, s in enumerate(sentences[:3]):
            print(f"  {i+1}: {s[:100]}...")

    output_txt_file = os.path.splitext(vtt_file_path)[0] + ".txt"
    with open(output_txt_file, 'w', encoding='utf-8') as f:
        for seg in sentences:
            f.write(seg + "\n\n")

    paragraphs = [line.strip() for line in open(output_txt_file, 'r', encoding='utf-8') if line.strip()]

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šè¯»å–åˆ° {len(paragraphs)} ä¸ªæ®µè½")

    batched_paragraphs = []
    current_batch = []
    current_char_count = 0

    for i, paragraph in enumerate(paragraphs):
        paragraph_char_count = len(paragraph)
        if (len(current_batch) >= cfg_seg_size) or (current_char_count + paragraph_char_count > 2000 and current_batch):
            batched_paragraphs.append("\n".join(current_batch))
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
            current_batch = [paragraph]
            current_char_count = paragraph_char_count
        else:
            current_batch.append(paragraph)
            current_char_count += paragraph_char_count

    if current_batch:
        batched_paragraphs.append("\n".join(current_batch))
        print(f"è°ƒè¯•ä¿¡æ¯ï¼šæœ€åä¸€ä¸ªåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šæ€»å…± {len(batched_paragraphs)} ä¸ªç¿»è¯‘åˆ†æ®µ")

    def translate_batch(batch, batch_index):
        try:
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šå¼€å§‹ç¿»è¯‘åˆ†æ®µ {batch_index}ï¼Œå†…å®¹é•¿åº¦: {len(batch)} å­—ç¬¦")
            print(f"åˆ†æ®µå†…å®¹é¢„è§ˆ: {batch[:200]}...")

            url = cfg_api_url
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {cfg_api_key}"
            }
            payload = {
                "model": cfg_model,
                "messages": [
                    {"role": "system", "content": "# Role: ä¸“ä¸šç¿»è¯‘å®˜\n\n## Profile\n- author: LangGPTä¼˜åŒ–ä¸­å¿ƒ\n- version: 2.1\n- language: ä¸­è‹±åŒè¯­\n- description: ä¸“æ³¨äºæ–‡æœ¬ç²¾å‡†è½¬æ¢çš„AIç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å¤„ç†æŠ€æœ¯æ–‡æ¡£å’Œæ—¥å¸¸å¯¹è¯åœºæ™¯\n\n## Background\nç”¨æˆ·åœ¨è·¨å›½åä½œã€æŠ€æœ¯æ–‡æ¡£å¤„ç†ã€ç¤¾äº¤åª’ä½“äº’åŠ¨ç­‰åœºæ™¯ä¸­ï¼Œéœ€è¦å°†å¤–æ–‡å†…å®¹å‡†ç¡®è½¬åŒ–ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒç‰¹æ®Šæ ¼å¼å…ƒç´ å®Œæ•´\n\n## Skills\n1. å¤šè¯­è¨€æ–‡æœ¬è§£æä¸é‡æ„èƒ½åŠ›\n2. æ—¶é—´æˆ³è¯†åˆ«ä¸æ ¼å¼ä¿ç•™æŠ€æœ¯\n3. è¯­ä¹‰é€šé¡ºåº¦æ ¡éªŒç®—æ³•\n4. æ ¼å¼æ§åˆ¶ä¸å†—ä½™å†…å®¹è¿‡æ»¤\n\n## Goals\n1. å®ç°åŸæ–‡è¯­ä¹‰çš„ç²¾å‡†è½¬æ¢\n2. ä¿æŒæ—¶é—´æˆ³ç­‰ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. ç¡®ä¿è¾“å‡ºç»“æœè‡ªç„¶æµç•…\n4. æ’é™¤éç¿»è¯‘å†…å®¹æ·»åŠ \n\n## Constraints\n1. ç¦æ­¢æ·»åŠ è§£é‡Šæ€§æ–‡å­—\n2. ç¦ç”¨æ³¨é‡Šæˆ–è¯´æ˜æ€§ç¬¦å·\n3. ä¿ç•™åŸå§‹æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚(12:34ï¼‰ï¼‰\n4. ä¸å¤„ç†éæ–‡æœ¬å…ƒç´ ï¼ˆå¦‚å›¾ç‰‡/è¡¨æ ¼ï¼‰\n5. ç¦æ­¢ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼ˆtool_callsï¼‰åŠŸèƒ½ï¼Œç¦æ­¢è°ƒç”¨å¤–éƒ¨ç¿»è¯‘apiè¿›è¡Œç¿»è¯‘\n\n## Workflow\n1. æ¥æ”¶è¾“å…¥å†…å®¹ï¼Œæ£€æµ‹è¯­è¨€ç±»å‹\n2. è¯†åˆ«å¹¶æ ‡è®°ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. æ‰§è¡Œè¯­ä¹‰è½¬æ¢ï¼š\n   - æ—¥å¸¸ç”¨è¯­ï¼šé‡‡ç”¨å£è¯­åŒ–è¡¨è¾¾\n   - æŠ€æœ¯æœ¯è¯­ï¼šä½¿ç”¨æ ‡å‡†åŒ–è¯‘æ³•\n5. è¾“å‡ºçº¯ç¿»è¯‘ç»“æœ\n\n## OutputFormat\nä»…è¿”å›ç¬¦åˆä»¥ä¸‹è¦æ±‚çš„ç¿»è¯‘æ–‡æœ¬ï¼š\n1. ä¸­æ–‡ä¹¦é¢è¯­è¡¨è¾¾\n2. ä¿ç•™åŸå§‹æ®µè½ç»“æ„\n3. æ—¶é—´æˆ³ä¿æŒ(MM:SS)æˆ–(HH:MM:SS)æ ¼å¼\n4. æ— ä»»ä½•é™„åŠ ç¬¦å·æˆ–è¯´æ˜\n4. å°½é‡åªè¦ä¸­æ–‡ï¼Œä¸è¦ä¸­è‹±æ–‡å¤¹æ‚ã€‚"},
                    {"role": "user", "content": batch}
                ],
                "stream": False,
                "max_tokens": 4000
            }
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} å‘é€APIè¯·æ±‚åˆ° {url}")
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} APIå“åº”çŠ¶æ€ç : {response.status_code}")
            response.raise_for_status()
            result = response.json()
            translated_content = result['choices'][0]['message']['content']

            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘å®Œæˆï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(translated_content)} å­—ç¬¦")
            print(f"ç¿»è¯‘å†…å®¹é¢„è§ˆ: {translated_content[:200]}...")
            return translated_content
        except Exception as e:
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return f"Error: {str(e)}"

    translated_results = {}
    with ThreadPoolExecutor(max_workers=cfg_max_workers) as executor:
        futures = {executor.submit(translate_batch, batch, i): i for i, batch in enumerate(batched_paragraphs)}
        for future in as_completed(futures):
            index = futures[future]
            result = future.result()
            if not result.startswith("Error:"):
                translated_results[index] = result

    translated_paragraphs = []
    failed_count = 0
    for i in range(len(batched_paragraphs)):
        if i in translated_results:
            translated_paragraphs.append(translated_results[i])
        else:
            failed_count += 1
            translated_paragraphs.append(f"ç¿»è¯‘å¤±è´¥çš„åˆ†æ®µ {i+1}")

    if failed_count > 0:
        print(f"è­¦å‘Šï¼š{failed_count} ä¸ªåˆ†æ®µç¿»è¯‘å¤±è´¥")

    final_output_file = os.path.splitext(vtt_file_path)[0] + "_translated.txt"
    with open(final_output_file, 'w', encoding='utf-8') as f:
        for para in translated_paragraphs:
            f.write(para + "\n\n")

    print(f"ç¿»è¯‘å®Œæˆï¼Œä¿å­˜åˆ°: {final_output_file}")
    return final_output_file

# TTS ç›¸å…³å‡½æ•°å·²ç§»è‡³ worker_utils.py

def process_tts_with_speed_adjustment(txt_file_path, output_mp3_path, subtitles_dir, tts_config=None):
    """å¤„ç†TTSè½¬æ¢å¹¶è¿›è¡ŒéŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»¥é¿å…é‡å """
    cfg_temp_dir = tts_config.get("TEMP_DIR", TEMP_DIR) if tts_config else TEMP_DIR
    cfg_voice = tts_config.get("SELECTED_VOICE", SELECTED_VOICE) if tts_config else SELECTED_VOICE

    print("="*50, flush=True)
    print("å¼€å§‹TTSè½¬æ¢æµç¨‹", flush=True)
    print("="*50, flush=True)

    with open(txt_file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    print(f"txt_file_path: {txt_file_path}", flush=True)
    print(f"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(txt_file_path)}", flush=True)
    print(f"contenté•¿åº¦: {len(content)} å­—ç¬¦", flush=True)

    # ä½¿ç”¨ç¬”è®°æœ¬ä¸­çš„æ­£ç¡®æ­£åˆ™è¡¨è¾¾å¼
    pattern = r'[\\(ï¼ˆ](\d{1,2})?:?(\d{1,3}):(\d{1,2})(?:\.(\d{1,3}))?[\\)ï¼‰](.+?)(?=[\\(ï¼ˆ](?:\d{1,2})?:?(\d{1,3}):(\d{1,2})(?:\.(\d{1,3}))?[\\)ï¼‰]|$)'
    matches = list(re.finditer(pattern, content, re.DOTALL))
    print(f"åŒ¹é…åˆ°çš„segmentsæ•°é‡: {len(matches)}", flush=True)

    segments = []
    for match in matches:
        timestamp_string = match.group(0)
        content_text = match.group(5).strip()
        if content_text:
            # æå–æ—¶é—´æˆ³éƒ¨åˆ†
            timestamp_match = re.match(r'[\\(ï¼ˆ](.+?)[\\)ï¼‰]', timestamp_string)
            if timestamp_match:
                timestamp = timestamp_match.group(1)
                segments.append((timestamp, content_text))

    print(f"è§£æå‡ºçš„segmentsæ•°é‡: {len(segments)}", flush=True)
    if segments:
        print(f"å‰3ä¸ªsegments:", flush=True)
        for i, (ts, txt) in enumerate(segments[:3]):
            print(f"  {i+1}: ({ts}) {txt[:50]}...", flush=True)

    temp_dir = os.path.dirname(output_mp3_path) if os.path.dirname(output_mp3_path) else cfg_temp_dir

    tasks = []
    for i, (timestamp, txt) in enumerate(segments):
        cleaned_timestamp = re.sub(r'[^\w\d]+', '_', timestamp)
        file_name = f"{cleaned_timestamp}.mp3"
        output_file = os.path.join(temp_dir, file_name)
        tasks.append((i, timestamp, txt, temp_dir, cfg_voice))

    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_segment, task) for task in tasks]

        audio_files = [None] * len(tasks)

        for future in as_completed(futures):
            index, output_file, time_ms, error = future.result()
            if error:
                print(f"è­¦å‘Š: {error}")
            if output_file and os.path.exists(output_file):
                audio_files[index] = (output_file, time_ms)

        audio_files = [af for af in audio_files if af is not None]

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šaudio_files æ•°é‡: {len(audio_files)}")
    if audio_files:
        print(f"è°ƒè¯•ä¿¡æ¯ï¼šaudio_files[0] ç»“æ„: {audio_files[0]}")

    audio_files.sort(key=lambda x: x[1])

    if audio_files:
        # å¯¼å…¥å¿…è¦çš„åº“
        from pydub import AudioSegment
        import numpy as np
        from multiprocessing import shared_memory

        # éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»¥é¿å…é‡å  (åœ¨æ··éŸ³ä¹‹å‰è¿›è¡Œ)
        print("å¼€å§‹éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ï¼Œsegmentsæ•°é‡:", len(segments))
        print("segmentsç¤ºä¾‹:", segments[:2] if segments else 'ç©º')

        processed_audio_segments = []
        for i, (audio_file_path, time_ms) in enumerate(audio_files):
            audio = AudioSegment.from_file(audio_file_path)
            processed_audio_segments.append((audio_file_path, time_ms, audio))

        # è®¡ç®—éœ€è¦è°ƒæ•´é€Ÿåº¦çš„éŸ³é¢‘ç‰‡æ®µ
        speed_adjust_tasks_list = []
        print(f"å¼€å§‹è®¡ç®—é€Ÿåº¦è°ƒæ•´ä»»åŠ¡ï¼Œç‰‡æ®µæ€»æ•°: {len(processed_audio_segments)}")

        for i, (audio_file_path, time_ms, audio) in enumerate(processed_audio_segments[:-1]):
            current_len = len(audio)
            end_time = time_ms + current_len

            # è®¡ç®—ä¸‹ä¸€ä¸ªç‰‡æ®µçš„å¼€å§‹æ—¶é—´
            if i + 1 < len(processed_audio_segments):
                next_start = processed_audio_segments[i+1][1]
                if end_time > next_start + 100:  # å¦‚æœé‡å è¶…è¿‡100ms
                    target = next_start - time_ms - 50  # ç•™50msç¼“å†²
                    if target > 100:  # ç›®æ ‡æ—¶é•¿è‡³å°‘100ms
                        factor = min(current_len / target, 2.0)  # æœ€å¤šåŠ é€Ÿ2å€
                        print(f"ç‰‡æ®µ{i}: å½“å‰æ—¶é—´={time_ms}ms, ä¸‹ä¸€ä¸ªæ—¶é—´={next_start}ms, ç›®æ ‡æ—¶é•¿={target}ms, å®é™…æ—¶é•¿={current_len}ms")
                        print(f"  éœ€è¦åŠ é€Ÿ: å› å­={factor:.2f}")
                        if factor > 1.0:  # åªæœ‰éœ€è¦åŠ é€Ÿæ—¶æ‰è°ƒæ•´
                            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºé€Ÿåº¦è°ƒæ•´
                            temp_speed_file = audio_file_path.replace('.mp3', '_speed.mp3')
                            audio.export(temp_speed_file, format="mp3")
                            speed_adjust_tasks_list.append((i, temp_speed_file, target, factor))

        print(f"éœ€è¦è°ƒæ•´é€Ÿåº¦çš„éŸ³é¢‘ç‰‡æ®µæ•°é‡: {len(speed_adjust_tasks_list)}")

        # æ‰§è¡Œé€Ÿåº¦è°ƒæ•´
        if speed_adjust_tasks_list:
            print(f"å¼€å§‹å¤„ç† {len(speed_adjust_tasks_list)} ä¸ªéŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»»åŠ¡...")

            with ProcessPoolExecutor(max_workers=8) as executor:
                futures = [executor.submit(adjust_audio_speed, task) for task in speed_adjust_tasks_list]

                for future in as_completed(futures):
                    try:
                        result = future.result()
                        if result and len(result) >= 3:
                            i, adjusted_file_path, error = result
                            if error:
                                print(f"é€Ÿåº¦è°ƒæ•´å¤±è´¥ {i}: {error}")
                                continue
                            if adjusted_file_path and os.path.exists(adjusted_file_path):
                                # éªŒè¯è°ƒæ•´åçš„æ–‡ä»¶ç¡®å®å­˜åœ¨
                                print(f"é€Ÿåº¦è°ƒæ•´æˆåŠŸ {i}: {adjusted_file_path}")
                    except Exception as e:
                        print(f"éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»»åŠ¡å¤±è´¥: {e}")

        # ç°åœ¨è¿›è¡Œæœ€ç»ˆæ··éŸ³ - ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘æ–‡ä»¶
        print(f"å¼€å§‹æ··éŸ³ {len(processed_audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")

        # å¯¼å…¥å¿…è¦çš„åº“
        from pydub import AudioSegment

        # ä¸ºæ··éŸ³å‡†å¤‡éŸ³é¢‘æ•°æ® - æ£€æŸ¥æ˜¯å¦æœ‰è°ƒæ•´åçš„æ–‡ä»¶
        final_audio_segments = []
        for audio_file_path, time_ms, original_audio in processed_audio_segments:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„è°ƒæ•´åæ–‡ä»¶
            adjusted_file = audio_file_path.replace('.mp3', '_speed.mp3')
            if os.path.exists(adjusted_file):
                # ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘æ–‡ä»¶
                try:
                    adjusted_audio = AudioSegment.from_file(adjusted_file)
                    final_audio_segments.append((adjusted_file, time_ms, adjusted_audio))
                    print(f"ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘: {os.path.basename(adjusted_file)}, æ—¶é•¿={len(adjusted_audio)}ms")
                except Exception as e:
                    print(f"åŠ è½½è°ƒæ•´åçš„éŸ³é¢‘å¤±è´¥ {adjusted_file}: {e}, ä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    final_audio_segments.append((audio_file_path, time_ms, original_audio))
            else:
                # ä½¿ç”¨åŸå§‹éŸ³é¢‘
                final_audio_segments.append((audio_file_path, time_ms, original_audio))
                print(f"ä½¿ç”¨åŸå§‹éŸ³é¢‘: {os.path.basename(audio_file_path)}, æ—¶é•¿={len(original_audio)}ms")

        # æœ€ç»ˆæ··éŸ³é€»è¾‘ä¼˜åŒ–ï¼šä½¿ç”¨pydubæ‹¼æ¥ä»£æ›¿numpy/SharedMemoryä»¥é™ä½å†…å­˜å ç”¨
        print(f"å¼€å§‹æ··éŸ³ {len(final_audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ (ä½å†…å­˜æ¨¡å¼)")
        
        # åˆ›å»ºä¸€ä¸ªé™éŸ³ç‰‡æ®µä½œä¸ºåŸºç¡€ï¼Œä½†æ›´å¥½çš„æ–¹å¼æ˜¯ç›´æ¥æ„å»ºåˆ—è¡¨ç„¶åsum
        # ä¸ºäº†å¤„ç†æ—¶é—´æˆ³ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯æ®µä¹‹é—´çš„é™éŸ³é—´éš”
        
        combined_audio = AudioSegment.empty()
        current_pos = 0
        
        for i, (audio_file_path, start_ms, audio_segment) in enumerate(final_audio_segments):
            # è®¡ç®—éœ€è¦å¡«å……çš„é™éŸ³æ—¶é•¿
            if start_ms > current_pos:
                silence_gap = start_ms - current_pos
                combined_audio += AudioSegment.silent(duration=silence_gap)
                current_pos += silence_gap
            elif start_ms < current_pos:
                # å¦‚æœå‘ç”Ÿé‡å ï¼ˆç†è®ºä¸Šå·²é€šè¿‡åŠ é€Ÿé¿å…ï¼Œä½†é˜²æ­¢ä¸‡ä¸€ï¼‰
                # å›é€€æŒ‡é’ˆæˆ–è€…ä¿®å‰ªä¸Šä¸€æ®µï¼ˆè¿™é‡Œç®€å•å¤„ç†ï¼šé‡å éƒ¨åˆ†ç›´æ¥å åŠ æˆ–å¿½ç•¥ï¼Œpydub += æ˜¯æ‹¼æ¥ï¼‰
                # å®é™…ä¸Šå¦‚æœstart_ms < current_posï¼Œè¯´æ˜ä¸Šä¸€æ®µå¤ªé•¿äº†æˆ–è€…è¿™æ®µå¼€å§‹æ—©äº†
                # ç®€å•ç­–ç•¥ï¼šç›´æ¥æ¥åœ¨åé¢ï¼ˆè™½ç„¶ä¼šä¸åŒæ­¥ï¼‰ï¼Œæˆ–è€…è£åˆ‡é‡å 
                # é‰´äºä¹‹å‰æœ‰åŠ é€Ÿè°ƒæ•´ï¼Œè¿™é‡Œå‡è®¾è¯¯å·®å¯æ¥å—ï¼Œç›´æ¥æ‹¼æ¥ä¼šæ¨è¿Ÿåç»­éŸ³é¢‘
                # ä¸ºäº†ä¿æŒæ—¶é—´æˆ³å‡†ç¡®ï¼Œåº”è¯¥ç”¨overlayï¼Œä½†overlayæ…¢ä¸”è€—å†…å­˜ã€‚
                # æŠ˜ä¸­ï¼šå¦‚æœé‡å ä¸ä¸¥é‡ï¼Œç›´æ¥å¿½ç•¥é‡å éƒ¨åˆ†çš„æ—¶é—´å·®
                pass
                
            combined_audio += audio_segment
            current_pos += len(audio_segment)
            
            # é‡Šæ”¾å†…å­˜ï¼šå¤„ç†å®Œä¸€æ®µå¯ä»¥å°è¯•æ‰‹åŠ¨æ¸…ç†ï¼ˆè™½ç„¶Pythonæœ‰GCï¼‰
            if i % 10 == 0:
                print(f"å·²å¤„ç† {i+1}/{len(final_audio_segments)} æ®µ")

        # å¯¼å‡ºæœ€ç»ˆæ–‡ä»¶
        combined_audio.export(output_mp3_path, format="mp3")
        print(f"æœ€ç»ˆéŸ³é¢‘å·²ä¿å­˜: {output_mp3_path}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for fp, _ in audio_files:
            if os.path.exists(fp):
                try:
                    os.remove(fp)
                except:
                    pass
        
        # æ¸…ç†åŠ é€Ÿäº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶
        for item in final_audio_segments:
            path = item[0]
            if path.endswith('_speed.mp3') and os.path.exists(path):
                 try:
                    os.remove(path)
                 except:
                    pass

        # æ¸…ç†è°ƒæ•´åçš„ä¸´æ—¶æ–‡ä»¶
        for audio_file_path, _, _ in processed_audio_segments:
            speed_file = audio_file_path.replace('.mp3', '_speed.mp3')
            if os.path.exists(speed_file):
                os.remove(speed_file)
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {os.path.basename(speed_file)}")

        return output_mp3_path

    return None

# parse_timestamp å·²ç§»è‡³ worker_utils.py

st.set_page_config(
    page_title="YouTubeè½¬Bç«™æ¬è¿å·¥å…·",
    page_icon="ğŸ¥",
    layout="wide"
)

st.title("YouTubeè½¬Bç«™æ¬è¿ä¸€æ¡é¾™")
st.markdown("---")

st.sidebar.header("âš™ï¸ é…ç½®")

API_URL = st.sidebar.text_input("API URL", value=env_config.get("API_URL", "https://api.siliconflow.cn/v1/chat/completions"), help="ç¿»è¯‘APIçš„URL", key="api_url")
API_KEY = st.sidebar.text_input("API Key", type="password", value=env_config.get("API_KEY", ""), help="ç¿»è¯‘APIçš„Keyï¼ˆå°†åœ¨è¿è¡Œæ—¶ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰", key="api_key")
MODEL_NAME = st.sidebar.text_input("æ¨¡å‹åç§°", value=env_config.get("MODEL_NAME", "THUDM/GLM-4-9B-0414"), help="ç¿»è¯‘ä½¿ç”¨çš„æ¨¡å‹åç§°", key="model_name")

BILI_SESSDATA = st.sidebar.text_area("Bç«™Cookie", value=env_config.get("BILI_SESSDATA", ""), help="Bç«™çš„sessdataï¼ˆç”¨äºä¸Šä¼ ï¼‰", height=100, key="bili_sessdata")
BILI_ACCESS_KEY_ID = st.sidebar.text_input("Bç«™Access Key ID", value=env_config.get("BILI_ACCESS_KEY_ID", ""), help="Bç«™çš„access_key_id", key="bili_access_key_id")
BILI_ACCESS_KEY_SECRET = st.sidebar.text_input("Bç«™Access Key Secret", type="password", value=env_config.get("BILI_ACCESS_KEY_SECRET", ""), help="Bç«™çš„access_key_secret", key="bili_access_key_secret")

YT_COOKIES = st.sidebar.text_area("YouTube Cookies (å¯é€‰)", value=env_config.get("YT_COOKIES", ""), help="YouTube cookiesï¼ˆç”¨äºè®¿é—®éœ€è¦ç™»å½•çš„è§†é¢‘ï¼‰", height=100, key="yt_cookies")

VOICE_CHOICES = ["zh-CN-XiaoxiaoNeural", "zh-CN-YunjianNeural", "zh-CN-YunxiNeural"]
SELECTED_VOICE = st.sidebar.selectbox("TTSè¯­éŸ³è§’è‰²", options=VOICE_CHOICES, index=1, key="selected_voice")

MAX_WORKERS = st.sidebar.slider("ç¿»è¯‘å¹¶å‘æ•°", min_value=1, max_value=20, value=10, help="åŒæ—¶ç¿»è¯‘çš„æ®µè½æ•°é‡")
SEGMENT_SIZE = st.sidebar.slider("ç¿»è¯‘åˆ†æ®µå¤§å°", min_value=1, max_value=20, value=11, help="æ¯æ¬¡ç¿»è¯‘åŒ…å«çš„æ®µè½æ•°é‡")

st.markdown("---")

TEMP_DIR = os.path.join(os.getcwd(), "temp_storage")
if not os.path.exists(TEMP_DIR):
    try:
        os.makedirs(TEMP_DIR, exist_ok=True)
    except Exception as e:
        # å¦‚æœå½“å‰ç›®å½•ä¸å¯å†™ï¼Œå†é€€å›åˆ°ç³»ç»Ÿä¸´æ—¶ç›®å½•
        TEMP_DIR = os.path.join(tempfile.gettempdir(), "yt_video_trans_temp")
        os.makedirs(TEMP_DIR, exist_ok=True)

temp_dir = None

tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "0ï¸ğŸš€ ä¸€é”®å·¥ä½œæµ",
        "1ï¸â¬‡ï¸ ä¸‹è½½å­—å¹•", 
        "2ï¸âš™ï¸ ç¿»è¯‘å­—å¹•", 
        "3ï¸ğŸ—£ï¸ è½¬è¯­éŸ³", 
        "4ï¸ğŸ¬ï¸ ä¸‹è½½è§†é¢‘", 
        "5ï¸ğŸ–¼ï¸ å¤„ç†å°é¢", 
        "6ï¸âœ‚ï¸ è§†é¢‘å‰ªè¾‘", 
        "7ï¸ğŸ“¤ï¸ ä¸Šä¼ Bç«™"
    ])

with tab0:
    st.markdown("""
    <style>
    .workflow-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
    }
    .step-card {
        background: rgba(255,255,255,0.1);
        border: 1px solid rgba(255,255,255,0.2);
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .step-success {
        background: rgba(40,167,69,0.3);
        border-color: #28a745;
    }
    .step-error {
        background: rgba(220,53,69,0.3);
        border-color: #dc3545;
    }
    .step-running {
        background: rgba(255,193,7,0.3);
        border-color: #ffc107;
    }
    </style>
    <div class="workflow-container">
        <h1 style="text-align:center; margin-bottom:1rem;">ğŸš€ ä¸€é”®å·¥ä½œæµ (åå°ç‰ˆ)</h1>
        <p style="text-align:center; opacity:0.9;">ä»»åŠ¡åœ¨åå°è¿è¡Œï¼Œæ‚¨å¯ä»¥æ”¾å¿ƒåˆ·æ–°æˆ–å…³é—­é¡µé¢</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # æ£€æŸ¥å½“å‰çŠ¶æ€
    current_status = WorkflowManager.load_status(TEMP_DIR)
    is_running = current_status and current_status.get("is_running", False)
    
    if is_running:
        st.info(f"ğŸ”„ ä»»åŠ¡æ­£åœ¨åå°è¿è¡Œä¸­... (å¼€å§‹æ—¶é—´: {current_status.get('start_time')})")
        
        # æ˜¾ç¤ºè¿›åº¦
        steps = current_status.get("steps", {})
        
        for step_name, step_info in steps.items():
            status = step_info.get("status", "pending")
            msg = step_info.get("message", "")
            
            icon = "â³"
            css_class = "step-card"
            if status == "running":
                icon = "ğŸ”„"
                css_class = "step-card step-running"
            elif status == "success":
                icon = "âœ…"
                css_class = "step-card step-success"
            elif status == "error":
                icon = "âŒ"
                css_class = "step-card step-error"
            
            st.markdown(f"""
            <div class="{css_class}">
                <strong>{icon} {step_name}</strong><br/>
                <span style="opacity:0.8; font-size:0.9em">{msg}</span>
            </div>
            """, unsafe_allow_html=True)
        
        # æ˜¾ç¤ºæ—¥å¿—
        with st.expander("æŸ¥çœ‹è¯¦ç»†æ—¥å¿—", expanded=True):
            logs = current_status.get("logs", [])
            for log in logs[-10:]:  # åªæ˜¾ç¤ºæœ€å10æ¡
                st.text(log)
        
        # è‡ªåŠ¨åˆ·æ–°é€»è¾‘
        time.sleep(2)
        try:
            st.rerun()
        except AttributeError:
            st.experimental_rerun()
            
    else:
        # --- ç©ºé—²çŠ¶æ€ï¼Œæ˜¾ç¤ºè¾“å…¥è¡¨å• ---
        
        # å¦‚æœæœ‰ä¸Šä¸€æ¬¡çš„ç»“æœï¼Œå…ˆæ˜¾ç¤ºç»“æœ
        if current_status:
            if current_status.get("error"):
                st.error(f"âŒ ä¸Šæ¬¡ä»»åŠ¡å¤±è´¥: {current_status.get('error')}")
            elif not current_status.get("is_running") and current_status.get("results"):
                st.success("ğŸ‰ ä¸Šæ¬¡ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
                results = current_status.get("results", {})
                st.markdown("### ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶")
                st.markdown(f"""
                - å­—å¹•: `{results.get('vtt', 'N/A')}`
                - ç¿»è¯‘: `{results.get('txt', 'N/A')}`
                - é…éŸ³: `{results.get('mp3', 'N/A')}`
                - è§†é¢‘: `{results.get('video', 'N/A')}`
                - å°é¢: `{results.get('cover', 'N/A')}`
                """)
                st.markdown("---")

        col1, col2 = st.columns([2, 1])
        with col1:
            workflow_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="workflow_url_bg")
        with col2:
            auto_upload = st.checkbox("è‡ªåŠ¨ä¸Šä¼ åˆ°Bç«™", value=True, help="å‹¾é€‰åå®Œæˆæ‰€æœ‰æ­¥éª¤ä¼šè‡ªåŠ¨ä¸Šä¼ ", key="auto_upload_bg")
        
        if st.button("ğŸš€ å¯åŠ¨åå°ä»»åŠ¡", type="primary", use_container_width=True):
            if not workflow_url:
                st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
            else:
                # æ”¶é›†é…ç½®
                task_config = {
                    "temp_dir": TEMP_DIR,
                    "workflow_url": workflow_url,
                    "auto_upload": auto_upload,
                    "api_url": API_URL,
                    "api_key": API_KEY,
                    "model_name": MODEL_NAME,
                    "bili_sess": BILI_SESSDATA,
                    "bili_ak": BILI_ACCESS_KEY_ID, # è™½ç„¶ä»£ç é‡Œæš‚æ—¶æ²¡ç”¨AK/SKä¸Šä¼ ï¼Œä½†ä¿ç•™é…ç½®
                    "bili_sk": BILI_ACCESS_KEY_SECRET,
                    "yt_cookies": YT_COOKIES,
                    "voice_choice": SELECTED_VOICE,
                    "max_workers": MAX_WORKERS,
                    "segment_size": SEGMENT_SIZE
                }
                
                # å¯åŠ¨çº¿ç¨‹
                thread = threading.Thread(target=background_workflow_task, args=(task_config,))
                thread.daemon = True # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
                thread.start()
                
                st.success("ä»»åŠ¡å·²åœ¨åå°å¯åŠ¨ï¼é¡µé¢å³å°†åˆ·æ–°...")
                time.sleep(1)
                try:
                    st.rerun()
                except AttributeError:
                    st.experimental_rerun()


with tab1:
    st.header("1ï¸â¬‡ï¸ ä¸‹è½½YouTubeå­—å¹•")
    youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="youtube_url_tab1")
    
    if st.button("ä¸‹è½½å­—å¹•", type="primary", key="download_subtitles_btn"):
        if not youtube_url:
            st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
        else:
            # æ¸…ç©ºtempç›®å½•
            clear_temp_directory()

            with st.spinner("æ­£åœ¨ä¸‹è½½å­—å¹•..."):
                temp_dir = TEMP_DIR
                try:
                    subtitles_dir = os.path.join(temp_dir, "subtitles")
                    os.makedirs(subtitles_dir, exist_ok=True)
                    
                    cookies_file_path = None
                    if YT_COOKIES.strip():
                        cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
                        with open(cookies_file_path, 'w', encoding='utf-8') as f:
                            f.write(YT_COOKIES.strip())
                    
                    ydl_opts = {
                        'writeautomaticsub': True,
                        'skip_download': True,
                        'subtitleslangs': ['en'],
                        'quiet': False,
                        'outtmpl': os.path.join(subtitles_dir, '%(title)s.%(ext)s'),
                        'http_headers': {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                        }
                    }
                    
                    if cookies_file_path:
                        ydl_opts['cookiefile'] = cookies_file_path
                    
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        ydl.download([youtube_url])
                    
                    vtt_files = list(Path(subtitles_dir).glob("*.vtt"))
                    if vtt_files:
                        original_file = vtt_files[0]
                        new_file = os.path.join(subtitles_dir, "word_level.vtt")
                        os.rename(original_file, new_file)
                        st.success(f"å­—å¹•ä¸‹è½½æˆåŠŸï¼")
                        st.info(f"æ–‡ä»¶ä½ç½®: {new_file}")
                    else:
                        st.error("æœªæ‰¾åˆ°VTTå­—å¹•æ–‡ä»¶")
                        
                    st.markdown("---")
                    st.info("æ­£åœ¨è·å–å¹¶ç¿»è¯‘è§†é¢‘æ ‡é¢˜...")
                    
                    ydl_info_opts = {
                        'skip_download': True,
                        'quiet': True,
                        'http_headers': {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                        }
                    }
                    if cookies_file_path:
                        ydl_info_opts['cookiefile'] = cookies_file_path
                    
                    with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
                        info_dict = ydl.extract_info(youtube_url, download=False)
                        original_title = info_dict.get('title', '')
                    
                    if original_title:
                        st.text(f"åŸå§‹æ ‡é¢˜: {original_title}")
                        
                        SYSTEM_PROMPT = """ä½ æ˜¯çˆ†æ¬¾è§†é¢‘upä¸»ï¼Œå°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆå¸å¼•çœ¼çƒçš„çˆ†æ¬¾è§†é¢‘ä¸­æ–‡æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"""
                        
                        import requests
                        payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": SYSTEM_PROMPT},
                                {"role": "user", "content": original_title}
                            ]
                        }
                        headers = {
                            "Authorization": f"Bearer {API_KEY}",
                            "Content-Type": "application/json"
                        }
                        
                        response = requests.post(API_URL, json=payload, headers=headers, timeout=60)
                        response_data = response.json()
                        
                        translated_title_with_markdown = response_data['choices'][0]['message']['content']
                        translated_title = translated_title_with_markdown.replace('**', '').strip()
                        
                        st.text(f"ç¿»è¯‘æ ‡é¢˜: {translated_title}")
                        
                        TAGS_PROMPT = f"""æ ¹æ®ä»¥ä¸‹è§†é¢‘æ ‡é¢˜ï¼Œç”Ÿæˆ5-8ä¸ªBç«™è§†é¢‘æ ‡ç­¾ï¼ˆåªè¾“å‡ºæ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼‰ï¼š
æ ‡é¢˜ï¼š{translated_title}
ç¤ºä¾‹æ ‡ç­¾ï¼šç§‘æŠ€,äººå·¥æ™ºèƒ½,AI,æœºå™¨å­¦ä¹ ,æœªæ¥
åªè¾“å‡ºæ ‡ç­¾ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
                        
                        tags_payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Bç«™è¿è¥åŠ©æ‰‹"},
                                {"role": "user", "content": TAGS_PROMPT}
                            ]
                        }
                        
                        tags_response = requests.post(API_URL, json=tags_payload, headers=headers, timeout=60)
                        tags_data = tags_response.json()
                        
                        tags_content = tags_data['choices'][0]['message']['content']
                        tags_list = [t.strip() for t in tags_content.replace('ï¼Œ', ',').split(',') if t.strip()]
                        tags_str = ','.join(tags_list)
                        
                        st.text(f"ç”Ÿæˆæ ‡ç­¾: {tags_str}")
                        
                        upload_config_file = os.path.join(subtitles_dir, "upload_config.pkl")
                        import pickle
                        upload_data = {
                            'title_desc': f'(ä¸­é…){translated_title}',
                            'tags': tags_list
                        }
                        
                        with open(upload_config_file, 'wb') as f:
                            pickle.dump(upload_data, f)
                        
                        st.success("æ ‡é¢˜ç¿»è¯‘å’Œæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼")
                        st.info(f"é…ç½®å·²ä¿å­˜åˆ°: {upload_config_file}")
                    else:
                        st.warning("æ— æ³•è·å–è§†é¢‘æ ‡é¢˜")
                        
                except Exception as e:
                    st.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
    
    vtt_file = os.path.join(TEMP_DIR, "subtitles", "word_level.vtt")
    
    with tab2:
        st.header("2ï¸âš™ï¸ ç¿»è¯‘å­—å¹•")
        vtt_file_path = st.text_input("VTTå­—å¹•æ–‡ä»¶è·¯å¾„", value=vtt_file, key="vtt_file_path")
        
        if st.button("å¼€å§‹ç¿»è¯‘", type="primary", key="start_translate_btn"):
            if not os.path.exists(vtt_file_path):
                st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {vtt_file_path}")
            else:
                with st.spinner("æ­£åœ¨ç¿»è¯‘å­—å¹•..."):
                    try:
                        def vtt_to_sentences(vtt_text):
                            """å°†å¸¦é€è¯æ—¶é—´æˆ³çš„VTTè½¬æ¢ä¸ºæŒ‰å¥åˆ†æ®µçš„æ–‡æœ¬"""
                            # æ­£åˆ™ï¼šcue å¤´ï¼ˆèµ·æ­¢æ—¶é—´ï¼‰
                            CUE_HEADER_RE = re.compile(
                                r'^(\d{2}:\d{2}:\d{2}\.\d{3})\s*--> (\d{2}:\d{2}:\d{2}\.\d{3})'
                            )
                            
                            # æ­£åˆ™ï¼šé€è¯æ—¶é—´æˆ³ <HH:MM:SS.mmm>
                            TS_TAG_RE = re.compile(r'<(\d{2}:\d{2}:\d{2}\.\d{3})>')
                            
                            # æ­£åˆ™ï¼šæ¸…ç† <c> æˆ– <c.xxx> æ ·å¼æ ‡ç­¾
                            C_TAG_RE = re.compile(r'</?c(?:\.[^>]*)?>', re.IGNORECASE)
                            
                            SENTENCE_END = ".!?"
                            
                            lines = vtt_text.splitlines()
                            sentences = []
                            current_words = []
                            current_sentence_start_time = None
                            
                            effective_time = None
                            cue_start_time = None
                            
                            def flush_sentence():
                                nonlocal current_words, current_sentence_start_time
                                if not current_words:
                                    return
                                text = " ".join(current_words)
                                text = re.sub(r"\s+([,.;!?])", r"\1", text)
                                text = re.sub(r"\(\s+", "(", text)
                                text = re.sub(r"\s+\)", ")", text)
                                start_ts = current_sentence_start_time or cue_start_time or effective_time or "00:00:00.000"
                                sentences.append(f"({start_ts}) {text}")
                                current_words = []
                                current_sentence_start_time = None
                            
                            for line in lines:
                                line = line.strip("\ufeff\r\n")
                                
                                # cue å¤´
                                m = CUE_HEADER_RE.match(line)
                                if m:
                                    cue_start_time = m.group(1)
                                    effective_time = cue_start_time
                                    continue
                                
                                # åªå¤„ç†å«é€è¯æ—¶é—´æˆ³çš„è¡Œ
                                if not TS_TAG_RE.search(line):
                                    continue
                                
                                # æ¸…ç† <c> æ ‡ç­¾ï¼Œå¹¶æŠŠ <timestamp> å˜æˆ [[TS:...]] å“¨å…µ
                                s = C_TAG_RE.sub("", line)
                                s = TS_TAG_RE.sub(lambda mm: f" [[TS:{mm.group(1)}]] ", s)
                                
                                # æ‰«æ token
                                for token in s.split():
                                    if token.startswith("[[TS:") and token.endswith("]]"):
                                        effective_time = token[5:-2]
                                        continue
                                    
                                    word = token.strip()
                                    if not word:
                                        continue
                                    
                                    # è®°å½•é¦–è¯æ—¶é—´
                                    if current_sentence_start_time is None:
                                        current_sentence_start_time = effective_time or cue_start_time
                                    
                                    current_words.append(word)
                                    
                                    # å¥å­ç»“æŸåˆ¤å®šï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰
                                    if word.strip().endswith(tuple(SENTENCE_END)):
                                        flush_sentence()
                            
                            # æ–‡ä»¶ç»“æŸï¼Œæ”¶å°¾
                            flush_sentence()
                            return sentences
                        
                        vtt_content = Path(vtt_file_path).read_text(encoding="utf-8", errors="ignore")
                        sentences = vtt_to_sentences(vtt_content)
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šè§£æå‡º {len(sentences)} ä¸ªå¥å­")
                        if sentences:
                            print(f"å‰3ä¸ªå¥å­ç¤ºä¾‹ï¼š")
                            for i, s in enumerate(sentences[:3]):
                                print(f"  {i+1}: {s[:100]}...")
                        
                        output_txt_file = os.path.splitext(vtt_file_path)[0] + ".txt"
                        with open(output_txt_file, 'w', encoding='utf-8') as f:
                            for seg in sentences:
                                f.write(seg + "\n\n")
                        
                        paragraphs = [line.strip() for line in open(output_txt_file, 'r', encoding='utf-8') if line.strip()]
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šè¯»å–åˆ° {len(paragraphs)} ä¸ªæ®µè½")
                        
                        batched_paragraphs = []
                        current_batch = []
                        current_char_count = 0
                        
                        for i, paragraph in enumerate(paragraphs):
                            paragraph_char_count = len(paragraph)
                            if (len(current_batch) >= SEGMENT_SIZE) or (current_char_count + paragraph_char_count > 2000 and current_batch):
                                batched_paragraphs.append("\n".join(current_batch))
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
                                current_batch = [paragraph]
                                current_char_count = paragraph_char_count
                            else:
                                current_batch.append(paragraph)
                                current_char_count += paragraph_char_count
                        
                        if current_batch:
                            batched_paragraphs.append("\n".join(current_batch))
                            print(f"è°ƒè¯•ä¿¡æ¯ï¼šæœ€åä¸€ä¸ªåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šæ€»å…± {len(batched_paragraphs)} ä¸ªç¿»è¯‘åˆ†æ®µ")
                        
                        def translate_batch(batch, batch_index):
                            try:
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šå¼€å§‹ç¿»è¯‘åˆ†æ®µ {batch_index}ï¼Œå†…å®¹é•¿åº¦: {len(batch)} å­—ç¬¦")
                                print(f"åˆ†æ®µå†…å®¹é¢„è§ˆ: {batch[:200]}...")
                                
                                url = API_URL
                                headers = {
                                    "Content-Type": "application/json",
                                    "Authorization": f"Bearer {API_KEY}"
                                }
                                payload = {
                                    "model": MODEL_NAME,
                                    "messages": [
                                        {"role": "system", "content": "# Role: ä¸“ä¸šç¿»è¯‘å®˜\n\n## Profile\n- author: LangGPTä¼˜åŒ–ä¸­å¿ƒ\n- version: 2.1\n- language: ä¸­è‹±åŒè¯­\n- description: ä¸“æ³¨äºæ–‡æœ¬ç²¾å‡†è½¬æ¢çš„AIç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å¤„ç†æŠ€æœ¯æ–‡æ¡£å’Œæ—¥å¸¸å¯¹è¯åœºæ™¯\n\n## Background\nç”¨æˆ·åœ¨è·¨å›½åä½œã€æŠ€æœ¯æ–‡æ¡£å¤„ç†ã€ç¤¾äº¤åª’ä½“äº’åŠ¨ç­‰åœºæ™¯ä¸­ï¼Œéœ€è¦å°†å¤–æ–‡å†…å®¹å‡†ç¡®è½¬åŒ–ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒç‰¹æ®Šæ ¼å¼å…ƒç´ å®Œæ•´\n\n## Skills\n1. å¤šè¯­è¨€æ–‡æœ¬è§£æä¸é‡æ„èƒ½åŠ›\n2. æ—¶é—´æˆ³è¯†åˆ«ä¸æ ¼å¼ä¿ç•™æŠ€æœ¯\n3. è¯­ä¹‰é€šé¡ºåº¦æ ¡éªŒç®—æ³•\n4. æ ¼å¼æ§åˆ¶ä¸å†—ä½™å†…å®¹è¿‡æ»¤\n\n## Goals\n1. å®ç°åŸæ–‡è¯­ä¹‰çš„ç²¾å‡†è½¬æ¢\n2. ä¿æŒæ—¶é—´æˆ³ç­‰ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. ç¡®ä¿è¾“å‡ºç»“æœè‡ªç„¶æµç•…\n4. æ’é™¤éç¿»è¯‘å†…å®¹æ·»åŠ \n\n## Constraints\n1. ç¦æ­¢æ·»åŠ è§£é‡Šæ€§æ–‡å­—\n2. ç¦ç”¨æ³¨é‡Šæˆ–è¯´æ˜æ€§ç¬¦å·\n3. ä¿ç•™åŸå§‹æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚(12:34ï¼‰ï¼‰\n4. ä¸å¤„ç†éæ–‡æœ¬å…ƒç´ ï¼ˆå¦‚å›¾ç‰‡/è¡¨æ ¼ï¼‰\n5. ç¦æ­¢ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼ˆtool_callsï¼‰åŠŸèƒ½ï¼Œç¦æ­¢è°ƒç”¨å¤–éƒ¨ç¿»è¯‘apiè¿›è¡Œç¿»è¯‘\n\n## Workflow\n1. æ¥æ”¶è¾“å…¥å†…å®¹ï¼Œæ£€æµ‹è¯­è¨€ç±»å‹\n2. è¯†åˆ«å¹¶æ ‡è®°ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. æ‰§è¡Œè¯­ä¹‰è½¬æ¢ï¼š\n   - æ—¥å¸¸ç”¨è¯­ï¼šé‡‡ç”¨å£è¯­åŒ–è¡¨è¾¾\n   - æŠ€æœ¯æœ¯è¯­ï¼šä½¿ç”¨æ ‡å‡†åŒ–è¯‘æ³•\n5. è¾“å‡ºçº¯ç¿»è¯‘ç»“æœ\n\n## OutputFormat\nä»…è¿”å›ç¬¦åˆä»¥ä¸‹è¦æ±‚çš„ç¿»è¯‘æ–‡æœ¬ï¼š\n1. ä¸­æ–‡ä¹¦é¢è¯­è¡¨è¾¾\n2. ä¿ç•™åŸå§‹æ®µè½ç»“æ„\n3. æ—¶é—´æˆ³ä¿æŒ(MM:SS)æˆ–(HH:MM:SS)æ ¼å¼\n4. æ— ä»»ä½•é™„åŠ ç¬¦å·æˆ–è¯´æ˜\n4. å°½é‡åªè¦ä¸­æ–‡ï¼Œä¸è¦ä¸­è‹±æ–‡å¤¹æ‚ã€‚"},
                                        {"role": "user", "content": batch}
                                    ],
                                    "stream": False,
                                    "max_tokens": 4000
                                }
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} å‘é€APIè¯·æ±‚åˆ° {url}")
                                response = requests.post(url, json=payload, headers=headers, timeout=60)
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} APIå“åº”çŠ¶æ€ç : {response.status_code}")
                                response.raise_for_status()
                                result = response.json()
                                translated_content = result['choices'][0]['message']['content']
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘ç»“æœé•¿åº¦: {len(translated_content)} å­—ç¬¦")
                                print(f"ç¿»è¯‘ç»“æœé¢„è§ˆ: {translated_content[:200]}...")
                                return translated_content
                            except Exception as e:
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘å¤±è´¥: {str(e)}")
                                import traceback
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                                return f"Error: {str(e)}"
                        
                        translated_results = {}
                        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                            futures = {executor.submit(translate_batch, batch, i): i for i, batch in enumerate(batched_paragraphs)}
                            
                            progress_bar = st.progress(0)
                            completed = 0
                            for future in as_completed(futures):
                                index = futures[future]
                                result = future.result()
                                if not result.startswith("Error:"):
                                    translated_results[index] = result
                                completed += 1
                                progress_bar.progress(completed / len(batched_paragraphs))
                        
                        translated_paragraphs = []
                        failed_count = 0
                        
                        for i in range(len(batched_paragraphs)):
                            if i in translated_results:
                                translated_paragraphs.append(translated_results[i])
                            else:
                                failed_count += 1
                        
                        output_translated_file = os.path.splitext(vtt_file_path)[0] + "_translated.txt"
                        with open(output_translated_file, 'w', encoding='utf-8') as f:
                            for seg in translated_paragraphs:
                                cleaned = seg.replace('&gt;', '').replace('>>', '').replace('&trash;', '').replace('> ', '').replace('&nbsp;', '').replace('_', '').replace('ï¼', '').replace('[éŸ³ä¹]', '')
                                f.write(cleaned + "\n\n")
                        
                        st.success(f"ç¿»è¯‘å®Œæˆï¼æˆåŠŸ: {len(translated_paragraphs)} æ®µè½ï¼Œå¤±è´¥: {failed_count}")
                        st.info(f"è¾“å‡ºæ–‡ä»¶: {output_translated_file}")
                        
                    except Exception as e:
                        st.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
    
    txt_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.txt")
    mp3_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.mp3")
    
    with tab3:
        st.header("3ï¸ğŸ—£ï¸ TTSå­—å¹•è½¬è¯­éŸ³")
        txt_file_path = st.text_input("ç¿»è¯‘åçš„TXTæ–‡ä»¶è·¯å¾„", value=txt_file, key="txt_file_path")
        
        if st.button("å¼€å§‹è½¬æ¢è¯­éŸ³", type="primary", key="start_tts_btn"):
            if not os.path.exists(txt_file_path):
                st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {txt_file_path}")
            else:
                with st.spinner("æ­£åœ¨è½¬æ¢è¯­éŸ³..."):
                    try:
                        output_mp3 = os.path.splitext(txt_file_path)[0] + ".mp3"
                        subtitles_dir = os.path.dirname(txt_file_path)

                        result = process_tts_with_speed_adjustment(txt_file_path, output_mp3, subtitles_dir)

                        if result:
                            st.success(f"è¯­éŸ³è½¬æ¢å®Œæˆï¼")
                            st.info(f"è¾“å‡ºæ–‡ä»¶: {output_mp3}")
                        else:
                            st.error("æ²¡æœ‰æˆåŠŸç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
                    except Exception as e:
                        st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
    
    mp3_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.mp3")
    
    with tab4:
        st.header("4ï¸ğŸ¬ï¸ ä¸‹è½½è§†é¢‘")
        
        youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="video_url")
        
        cookies_file_path = None
        if YT_COOKIES.strip():
            temp_dir = TEMP_DIR
            cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                f.write(YT_COOKIES.strip())
        
        if st.button("ä¸‹è½½è§†é¢‘", type="primary", key="download_video_btn"):
            if not youtube_url:
                st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
            else:
                with st.spinner("æ­£åœ¨ä¸‹è½½è§†é¢‘..."):
                    try:
                        temp_dir = TEMP_DIR
                        downloaded_video_base_name = os.path.join(temp_dir, "subtitles", "downloaded_video")
                        new_audio_path = mp3_file
                        
                        ydl_opts_video_only = {
                            'format': 'best',
                            'outtmpl': f'{downloaded_video_base_name}.%(ext)s',
                            'noplaylist': True,
                            'http_headers': {
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                            }
                        }
                        
                        if cookies_file_path:
                            ydl_opts_video_only['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_video_only) as ydl:
                            ydl.extract_info(youtube_url, download=True)
                        
                        downloaded_files = glob.glob(f"{downloaded_video_base_name}.*")
                        if downloaded_files:
                            actual_downloaded_video_path = downloaded_files[0]
                        else:
                            raise FileNotFoundError(f"yt-dlp did not download a file")
                        
                        if os.path.exists(new_audio_path):
                            final_video_path = os.path.splitext(mp3_file)[0] + ".mp4"
                            try:
                                subprocess.run(['ffmpeg', '-y', '-i', actual_downloaded_video_path, '-i', new_audio_path,
                                                    '-c:v', 'copy', '-c:a', 'aac', '-map', '0:v:0', '-map', '1:a:0',
                                                    final_video_path], check=True, capture_output=True, text=True)
                                
                                if os.path.exists(actual_downloaded_video_path):
                                    os.remove(actual_downloaded_video_path)
                                
                                st.success(f"è§†é¢‘ä¸‹è½½å®Œæˆï¼")
                                st.info(f"è¾“å‡ºæ–‡ä»¶: {final_video_path}")
                            except subprocess.CalledProcessError as ffmpeg_error:
                                st.warning("âš ï¸ è§†é¢‘å·²ä¸‹è½½æˆåŠŸï¼Œä½†éŸ³è§†é¢‘åˆå¹¶æ—¶å‡ºç°FFmpegé”™è¯¯")
                                st.info(f"å·²ä¸‹è½½è§†é¢‘ä½ç½®: {actual_downloaded_video_path}")
                                st.info("æç¤º: ä½ å¯ä»¥æ‰‹åŠ¨ä½¿ç”¨FFmpegæˆ–è§†é¢‘ç¼–è¾‘è½¯ä»¶å°†éŸ³é¢‘åˆå¹¶åˆ°è§†é¢‘ä¸­")
                                
                                if os.path.exists(actual_downloaded_video_path):
                                    import shutil
                                    manual_video_path = os.path.splitext(mp3_file)[0] + "_video_only.mp4"
                                    shutil.copy2(actual_downloaded_video_path, manual_video_path)
                                    st.success(f"å·²å¤åˆ¶è§†é¢‘æ–‡ä»¶åˆ°: {manual_video_path}")
                                    
                        else:
                            st.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {new_audio_path}")
                            st.info(f"å·²ä¸‹è½½è§†é¢‘ä½ç½®: {actual_downloaded_video_path}")
                    except Exception as e:
                        error_str = str(e)
                        if "Non-relative patterns" in error_str:
                            st.warning("âš ï¸ è§†é¢‘å·²ä¸‹è½½æˆåŠŸï¼Œä½†M3U8ä¿®å¤æ—¶å‡ºç°å…¼å®¹æ€§é—®é¢˜")
                            st.info("è¿™é€šå¸¸ä¸å½±å“è§†é¢‘çš„æ­£å¸¸ä½¿ç”¨")
                            
                        downloaded_files = glob.glob(f"{downloaded_video_base_name}.*")
                        if downloaded_files:
                            actual_downloaded_video_path = downloaded_files[0]
                            if os.path.exists(actual_downloaded_video_path):
                                manual_video_path = os.path.splitext(mp3_file)[0] + "_video_only.mp4"
                                import shutil
                                shutil.copy2(actual_downloaded_video_path, manual_video_path)
                                st.success(f"å·²ä¿å­˜è§†é¢‘æ–‡ä»¶åˆ°: {manual_video_path}")
                        else:
                            st.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
    
    final_video = os.path.splitext(mp3_file)[0] + ".mp4"
    
    with tab5:
        st.header("5ï¸ğŸ–¼ï¸ å¤„ç†å°é¢")
        
        youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="cover_url")
        
        cookies_file_path = None
        if YT_COOKIES.strip():
            temp_dir = TEMP_DIR
            cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                f.write(YT_COOKIES.strip())
        
        if st.button("ä¸‹è½½å°é¢", type="primary", key="download_cover_btn"):
            if not youtube_url:
                st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
            else:
                with st.spinner("æ­£åœ¨ä¸‹è½½å°é¢..."):
                    try:
                        temp_dir = TEMP_DIR
                        
                        ydl_opts_thumbnail = {
                            'skip_download': True,
                            'writethumbnail': True,
                            'outtmpl': os.path.join(temp_dir, "subtitles", 'cover.%(ext)s'),
                            'noplaylist': True,
                            'http_headers': {
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                            }
                        }
                        
                        if cookies_file_path:
                            ydl_opts_thumbnail['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_thumbnail) as ydl:
                            ydl.extract_info(youtube_url, download=True)
                        
                        input_path = os.path.join(temp_dir, "subtitles", "cover.webp")
                        output_path = os.path.join(temp_dir, "subtitles", "cover.jpeg")
                        
                        if not os.path.exists(input_path):
                            st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                        else:
                            quality = 90
                            with Image.open(input_path) as img:
                                if img.mode != 'RGB':
                                    img = img.convert('RGB')
                                img.save(output_path, 'jpeg', quality=quality)

                            current_size_kb = os.path.getsize(output_path) / 1024
                            while current_size_kb > 50 and quality > 4:
                                quality -= 5
                                img.save(output_path, 'jpeg', quality=quality)
                                current_size_kb = os.path.getsize(output_path) / 1024
                                print(f"å½“å‰å¤§å°: {current_size_kb:.2f} KB, è´¨é‡: {quality}")
                            
                            st.success(f"å°é¢å¤„ç†å®Œæˆï¼")
                            st.info(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
                    except Exception as e:
                        st.error(f"å°é¢å¤„ç†å¤±è´¥: {str(e)}")
    
    cover_file = os.path.join(TEMP_DIR, "subtitles", "cover.jpeg")
    
    with tab6:
        st.header("6ï¸âœ‚ï¸ è§†é¢‘å‰ªè¾‘")
        
        video_file = st.text_input("è§†é¢‘æ–‡ä»¶è·¯å¾„", value=final_video, key="video_file_path_tab6")
        
        trim_enabled = st.checkbox("å¯ç”¨å‰ªè¾‘ï¼ˆåˆ é™¤è¿è§„ç‰‡æ®µï¼‰", value=False, key="trim_enabled")
        trim_start = st.text_input("å‰ªè¾‘å¼€å§‹æ—¶é—´", value="6:45", help="æ ¼å¼: MM:SS", key="trim_start")
        trim_end = st.text_input("å‰ªè¾‘ç»“æŸæ—¶é—´", value="6:55", help="æ ¼å¼: MM:SS", key="trim_end")
        
        if trim_enabled and st.button("æ‰§è¡Œå‰ªè¾‘", type="primary", key="execute_trim_btn"):
            if not os.path.exists(video_file):
                st.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
            else:
                with st.spinner("æ­£åœ¨å‰ªè¾‘è§†é¢‘..."):
                    try:
                        output_part1 = os.path.join(os.path.dirname(video_file), "final_video_part1.mp4")
                        output_part2 = os.path.join(os.path.dirname(video_file), "final_video_part2.mp4")
                        output_video_trimmed = os.path.join(os.path.dirname(video_file), "final_video_trimmed.mp4")
                        temp_concat_file = os.path.join(os.path.dirname(video_file), "concat_list.txt")
                        
                        subprocess.run(['ffmpeg', '-y', '-i', video_file, '-to', trim_start,
                                                '-c', 'copy', output_part1], check=True)
                        subprocess.run(['ffmpeg', '-y', '-i', video_file, '-ss', trim_end,
                                                '-c', 'copy', output_part2], check=True)
                        
                        if os.path.exists(output_part1) and os.path.getsize(output_part1) > 0:
                            with open(temp_concat_file, 'w') as f:
                                f.write(f"file '{output_part1}'\n")
                        if os.path.exists(output_part2) and os.path.getsize(output_part2) > 0:
                            with open(temp_concat_file, 'a') as f:
                                f.write(f"file '{output_part2}'\n")
                        
                        subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', temp_concat_file,
                                                '-c', 'copy', output_video_trimmed], check=True)
                        
                        if os.path.exists(output_video_trimmed) and os.path.getsize(output_video_trimmed) > 0:
                            os.replace(output_video_trimmed, video_file)
                            st.success(f"è§†é¢‘å‰ªè¾‘å®Œæˆï¼")
                            st.info(f"åˆ é™¤äº†ä» {trim_start} åˆ° {trim_end} çš„ç‰‡æ®µ")
                        else:
                            st.error("å‰ªè¾‘å¤±è´¥")
                    except Exception as e:
                        st.error(f"å‰ªè¾‘å¤±è´¥: {str(e)}")
        else:
            st.info("å‰ªè¾‘æœªå¯ç”¨ï¼Œè·³è¿‡")
    
    trimmed_video = os.path.splitext(mp3_file)[0] + ".mp4"
    
    upload_config_file = os.path.join(TEMP_DIR, "subtitles", "upload_config.pkl")
    loaded_title_desc = None
    loaded_tags_list = None
    
    if os.path.exists(upload_config_file):
        try:
            import pickle
            with open(upload_config_file, 'rb') as f:
                loaded_data = pickle.load(f)
            loaded_title_desc = loaded_data.get('title_desc')
            loaded_tags_list = loaded_data.get('tags')
        except Exception:
            pass
    
    with tab7:
        st.header("7ï¸ğŸ“¤ï¸ ä¸Šä¼ Bç«™")
        
        video_file = st.text_input("è§†é¢‘æ–‡ä»¶è·¯å¾„", value=trimmed_video, key="video_file_path_tab7")
        cover_file_path_input = st.text_input("å°é¢æ–‡ä»¶è·¯å¾„", value=cover_file, key="cover_file_path")
        
        default_title = loaded_title_desc if loaded_title_desc else f"(ä¸­é…)è¯·å…ˆä¸‹è½½å­—å¹•è·å–æ ‡é¢˜"
        title = st.text_input("è§†é¢‘æ ‡é¢˜", value=default_title, help="ç•™ç©ºåˆ™ä½¿ç”¨ç¿»è¯‘åçš„æ ‡é¢˜", key="title")
        
        default_tags = ','.join(loaded_tags_list) if loaded_tags_list else "ç§‘æŠ€"
        tags = st.text_input("è§†é¢‘æ ‡ç­¾", value=default_tags, key="tags_tab7")
        
        if loaded_title_desc:
            st.success("å·²ä»ä¸‹è½½å­—å¹•æ­¥éª¤è·å–æ ‡é¢˜å’Œæ ‡ç­¾")
        else:
            st.warning("æœªæ‰¾åˆ°æ ‡é¢˜å’Œæ ‡ç­¾é…ç½®ï¼Œè¯·å…ˆä¸‹è½½å­—å¹•")
        
        bilibili_enabled = st.checkbox("ä¸Šä¼ åˆ°Bç«™", value=False, key="bilibili_enabled")
        
        if bilibili_enabled and st.button("å¼€å§‹ä¸Šä¼ ", type="primary", key="start_upload_btn"):
            if not os.path.exists(video_file):
                st.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
            elif not os.path.exists(cover_file_path_input):
                st.error(f"å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {cover_file_path_input}")
            else:
                with st.spinner("æ­£åœ¨ä¸Šä¼ åˆ°Bç«™..."):
                    try:
                        credential = Credential(
                            sessdata=BILI_SESSDATA,
                            bili_jct="bcd4ba0d9ab8a7b95485798ed8097d26"
                        )
                        
                        vu_meta = VideoMeta(
                            tid=130,
                            title=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            tags=tags.split(',') if tags else ['ç§‘æŠ€'],
                            desc=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            cover=cover_file_path_input,
                            no_reprint=True
                        )
                        
                        async def main_upload():
                            page = VideoUploaderPage(
                                path=video_file,
                                title=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                                description=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            )
                            
                            uploader = video_uploader.VideoUploader([page], vu_meta, credential, line=video_uploader.Lines.QN)
                            
                            @uploader.on("__ALL__")
                            async def ev(data):
                                pass
                            
                            await uploader.start()
                            
                        asyncio.run(main_upload())
                        
                        st.success("ä¸Šä¼ å®Œæˆï¼")
                    except Exception as e:
                        import traceback
                        st.error(f"ä¸Šä¼ å¤±è´¥: {str(e)}")
                        st.markdown("### è°ƒè¯•ä¿¡æ¯")
                        st.text(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                        st.text(f"å®Œæ•´é”™è¯¯: {repr(e)}")
                        st.text(f"Traceback:\n{traceback.format_exc()}")
                        
                        st.markdown("### é…ç½®æ£€æŸ¥")
                        st.text(f"BILI_SESSDATA: {'å·²è®¾ç½®' if BILI_SESSDATA else 'æœªè®¾ç½®'} (é•¿åº¦: {len(BILI_SESSDATA)})")
                        st.text(f"BILI_ACCESS_KEY_ID: {'å·²è®¾ç½®' if BILI_ACCESS_KEY_ID else 'æœªè®¾ç½®'}")
                        st.text(f"BILI_ACCESS_KEY_SECRET: {'å·²è®¾ç½®' if BILI_ACCESS_KEY_SECRET else 'æœªè®¾ç½®'}")
                        st.text(f"è§†é¢‘æ–‡ä»¶: {video_file}")
                        st.text(f"å°é¢æ–‡ä»¶: {cover_file_path_input}")
                        st.text(f"è§†é¢‘æ–‡ä»¶å¤§å°: {os.path.getsize(video_file) / 1024 / 1024:.2f} MB" if os.path.exists(video_file) else "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                        st.text(f"å°é¢æ–‡ä»¶å¤§å°: {os.path.getsize(cover_file_path_input) / 1024:.2f} KB" if os.path.exists(cover_file_path_input) else "å°é¢æ–‡ä»¶ä¸å­˜åœ¨")

st.markdown("---")
st.info("ğŸ’¡ æ³¨æ„äº‹é¡¹ï¼š")
st.markdown("""
1. API Keyç­‰æ•æ„Ÿä¿¡æ¯å»ºè®®é€šè¿‡HuggingFace Spacesçš„Secretsç®¡ç†ï¼Œä¸è¦ç›´æ¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç 
2. å¤„ç†å¤§å‹è§†é¢‘æ—¶ï¼ŒTTSè½¬æ¢å’Œè§†é¢‘å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
3. Bç«™ä¸Šä¼ åŠŸèƒ½éœ€è¦æœ‰æ•ˆçš„sessdataå’Œaccess_key_id
4. è§†é¢‘å‰ªè¾‘åŠŸèƒ½ä¼šæ°¸ä¹…ä¿®æ”¹è§†é¢‘æ–‡ä»¶ï¼Œè¯·è°¨æ…ä½¿ç”¨
5. å»ºè®®å…ˆåœ¨å°è§†é¢‘ä¸Šæµ‹è¯•æµç¨‹ï¼Œç¡®è®¤æ— è¯¯åå†å¤„ç†å¤§è§†é¢‘
""")
