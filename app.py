# -*- coding: utf-8 -*-
import os
import re
import json
import time
import shutil
import subprocess
import asyncio
import glob
import random
from pathlib import Path
import tempfile
import zipfile
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from PIL import Image

import streamlit as st
import yt_dlp
import requests
import edge_tts
from bilibili_api import sync, video_uploader, Credential
from bilibili_api.video_uploader import VideoUploaderPage, VideoMeta
import pydub
import pickle

def load_env_config():
    """
    åŠ è½½é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡(HuggingFace Secrets)ï¼Œå…¶æ¬¡ä½¿ç”¨.envæ–‡ä»¶
    """
    config = {}
    
    # 1. å…ˆåŠ è½½ .env æ–‡ä»¶ (å¦‚æœæœ‰)
    env_file = os.path.join(os.getcwd(), ".env")
    if os.path.exists(env_file):
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        config[key.strip()] = value.strip()
        except Exception as e:
            print(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")

    # 2. å†åŠ è½½ç³»ç»Ÿç¯å¢ƒå˜é‡ (è¦†ç›– .env ä¸­çš„åŒåé…ç½®)
    # æˆ‘ä»¬å…³å¿ƒçš„ç‰¹å®šç¯å¢ƒå˜é‡åˆ—è¡¨
    target_keys = [
        "API_KEY", "API_URL", "MODEL_NAME", 
        "YT_COOKIES", 
        "BILI_SESSDATA", "BILI_BILI_JCT", "BILI_BUVID3", 
        "BILI_ACCESS_KEY_ID", "BILI_ACCESS_KEY_SECRET"
    ]
    
    for key in target_keys:
        env_val = os.getenv(key)
        if env_val:
            config[key] = env_val
            
    # å…¼å®¹æ—§çš„/æ‹¼å†™é”™è¯¯çš„å˜é‡å BILI_SESSIDATA -> BILI_SESSDATA
    if "BILI_SESSDATA" not in config and os.getenv("BILI_SESSIDATA"):
        config["BILI_SESSDATA"] = os.getenv("BILI_SESSIDATA")
            
    return config

env_config = load_env_config()

def clear_temp_directory():
    """æ¸…ç©ºtempç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹"""
    import shutil
    try:
        if os.path.exists(TEMP_DIR):
            for filename in os.listdir(TEMP_DIR):
                file_path = os.path.join(TEMP_DIR, filename)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                except Exception as e:
                    print(f'æ¸…ç©ºtempç›®å½•æ—¶å‡ºé”™ {file_path}: {e}')
            print("tempç›®å½•å·²æ¸…ç©º")
        else:
            os.makedirs(TEMP_DIR, exist_ok=True)
            print("tempç›®å½•å·²åˆ›å»º")
    except Exception as e:
        print(f"æ¸…ç©ºtempç›®å½•å¤±è´¥: {e}")

# ç¿»è¯‘å­—å¹•ç›¸å…³å‡½æ•°
def translate_subtitles_from_vtt(vtt_file_path):
    """ä»VTTæ–‡ä»¶ç¿»è¯‘å­—å¹•ï¼Œç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆå•æ­¥æ‰§è¡Œçš„å®Œæ•´é€»è¾‘ï¼‰"""
    def vtt_to_sentences(vtt_text):
        """å°†å¸¦é€è¯æ—¶é—´æˆ³çš„VTTè½¬æ¢ä¸ºæŒ‰å¥åˆ†æ®µçš„æ–‡æœ¬"""
        # æ­£åˆ™ï¼šcue å¤´ï¼ˆèµ·æ­¢æ—¶é—´ï¼‰
        CUE_HEADER_RE = re.compile(
            r'^(\d{2}:\d{2}:\d{2}\.\d{3})\s*--> (\d{2}:\d{2}:\d{2}\.\d{3})'
        )

        # æ­£åˆ™ï¼šé€è¯æ—¶é—´æˆ³ <HH:MM:SS.mmm>
        TS_TAG_RE = re.compile(r'<(\d{2}:\d{2}:\d{2}\.\d{3})>')

        # æ­£åˆ™ï¼šæ¸…ç† <c> æˆ– <c.xxx> æ ·å¼æ ‡ç­¾
        C_TAG_RE = re.compile(r'</?c(?:\.[^>]*)?>', re.IGNORECASE)

        SENTENCE_END = ".!?"

        lines = vtt_text.splitlines()
        sentences = []
        current_words = []
        current_sentence_start_time = None

        effective_time = None
        cue_start_time = None

        def flush_sentence():
            nonlocal current_words, current_sentence_start_time
            if not current_words:
                return
            text = " ".join(current_words)
            text = re.sub(r"\s+([,.;!?])", r"\1", text)
            text = re.sub(r"\(\s+", "(", text)
            text = re.sub(r"\s+\)", ")", text)
            start_ts = current_sentence_start_time or cue_start_time or effective_time or "00:00:00.000"
            sentences.append(f"({start_ts}) {text}")
            current_words = []
            current_sentence_start_time = None

        for line in lines:
            line = line.strip("\ufeff\r\n")

            # cue å¤´
            m = CUE_HEADER_RE.match(line)
            if m:
                cue_start_time = m.group(1)
                effective_time = cue_start_time
                continue

            # åªå¤„ç†å«é€è¯æ—¶é—´æˆ³çš„è¡Œ
            if not TS_TAG_RE.search(line):
                continue

            # æ¸…ç† <c> æ ‡ç­¾ï¼Œå¹¶æŠŠ <timestamp> å˜æˆ [[TS:...]] å“¨å…µ
            s = C_TAG_RE.sub("", line)
            s = TS_TAG_RE.sub(lambda mm: f" [[TS:{mm.group(1)}]] ", s)

            # æ‰«æ token
            for token in s.split():
                if token.startswith("[[TS:") and token.endswith("]]"):
                    effective_time = token[5:-2]
                    continue

                word = token.strip()
                if not word:
                    continue

                # è®°å½•é¦–è¯æ—¶é—´
                if current_sentence_start_time is None:
                    current_sentence_start_time = effective_time or cue_start_time

                current_words.append(word)

                # å¥å­ç»“æŸåˆ¤å®šï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰
                if word.strip().endswith(tuple(SENTENCE_END)):
                    flush_sentence()

        # æ–‡ä»¶ç»“æŸï¼Œæ”¶å°¾
        flush_sentence()
        return sentences

    vtt_content = Path(vtt_file_path).read_text(encoding="utf-8", errors="ignore")
    sentences = vtt_to_sentences(vtt_content)

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šè§£æå‡º {len(sentences)} ä¸ªå¥å­")
    if sentences:
        print(f"å‰3ä¸ªå¥å­ç¤ºä¾‹ï¼š")
        for i, s in enumerate(sentences[:3]):
            print(f"  {i+1}: {s[:100]}...")

    output_txt_file = os.path.splitext(vtt_file_path)[0] + ".txt"
    with open(output_txt_file, 'w', encoding='utf-8') as f:
        for seg in sentences:
            f.write(seg + "\n\n")

    paragraphs = [line.strip() for line in open(output_txt_file, 'r', encoding='utf-8') if line.strip()]

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šè¯»å–åˆ° {len(paragraphs)} ä¸ªæ®µè½")

    batched_paragraphs = []
    current_batch = []
    current_char_count = 0

    for i, paragraph in enumerate(paragraphs):
        paragraph_char_count = len(paragraph)
        if (len(current_batch) >= SEGMENT_SIZE) or (current_char_count + paragraph_char_count > 2000 and current_batch):
            batched_paragraphs.append("\n".join(current_batch))
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
            current_batch = [paragraph]
            current_char_count = paragraph_char_count
        else:
            current_batch.append(paragraph)
            current_char_count += paragraph_char_count

    if current_batch:
        batched_paragraphs.append("\n".join(current_batch))
        print(f"è°ƒè¯•ä¿¡æ¯ï¼šæœ€åä¸€ä¸ªåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šæ€»å…± {len(batched_paragraphs)} ä¸ªç¿»è¯‘åˆ†æ®µ")

    def translate_batch(batch, batch_index):
        try:
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šå¼€å§‹ç¿»è¯‘åˆ†æ®µ {batch_index}ï¼Œå†…å®¹é•¿åº¦: {len(batch)} å­—ç¬¦")
            print(f"åˆ†æ®µå†…å®¹é¢„è§ˆ: {batch[:200]}...")

            url = API_URL
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {API_KEY}"
            }
            payload = {
                "model": MODEL_NAME,
                "messages": [
                    {"role": "system", "content": "# Role: ä¸“ä¸šç¿»è¯‘å®˜\n\n## Profile\n- author: LangGPTä¼˜åŒ–ä¸­å¿ƒ\n- version: 2.1\n- language: ä¸­è‹±åŒè¯­\n- description: ä¸“æ³¨äºæ–‡æœ¬ç²¾å‡†è½¬æ¢çš„AIç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å¤„ç†æŠ€æœ¯æ–‡æ¡£å’Œæ—¥å¸¸å¯¹è¯åœºæ™¯\n\n## Background\nç”¨æˆ·åœ¨è·¨å›½åä½œã€æŠ€æœ¯æ–‡æ¡£å¤„ç†ã€ç¤¾äº¤åª’ä½“äº’åŠ¨ç­‰åœºæ™¯ä¸­ï¼Œéœ€è¦å°†å¤–æ–‡å†…å®¹å‡†ç¡®è½¬åŒ–ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒç‰¹æ®Šæ ¼å¼å…ƒç´ å®Œæ•´\n\n## Skills\n1. å¤šè¯­è¨€æ–‡æœ¬è§£æä¸é‡æ„èƒ½åŠ›\n2. æ—¶é—´æˆ³è¯†åˆ«ä¸æ ¼å¼ä¿ç•™æŠ€æœ¯\n3. è¯­ä¹‰é€šé¡ºåº¦æ ¡éªŒç®—æ³•\n4. æ ¼å¼æ§åˆ¶ä¸å†—ä½™å†…å®¹è¿‡æ»¤\n\n## Goals\n1. å®ç°åŸæ–‡è¯­ä¹‰çš„ç²¾å‡†è½¬æ¢\n2. ä¿æŒæ—¶é—´æˆ³ç­‰ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. ç¡®ä¿è¾“å‡ºç»“æœè‡ªç„¶æµç•…\n4. æ’é™¤éç¿»è¯‘å†…å®¹æ·»åŠ \n\n## Constraints\n1. ç¦æ­¢æ·»åŠ è§£é‡Šæ€§æ–‡å­—\n2. ç¦ç”¨æ³¨é‡Šæˆ–è¯´æ˜æ€§ç¬¦å·\n3. ä¿ç•™åŸå§‹æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚(12:34ï¼‰ï¼‰\n4. ä¸å¤„ç†éæ–‡æœ¬å…ƒç´ ï¼ˆå¦‚å›¾ç‰‡/è¡¨æ ¼ï¼‰\n5. ç¦æ­¢ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼ˆtool_callsï¼‰åŠŸèƒ½ï¼Œç¦æ­¢è°ƒç”¨å¤–éƒ¨ç¿»è¯‘apiè¿›è¡Œç¿»è¯‘\n\n## Workflow\n1. æ¥æ”¶è¾“å…¥å†…å®¹ï¼Œæ£€æµ‹è¯­è¨€ç±»å‹\n2. è¯†åˆ«å¹¶æ ‡è®°ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. æ‰§è¡Œè¯­ä¹‰è½¬æ¢ï¼š\n   - æ—¥å¸¸ç”¨è¯­ï¼šé‡‡ç”¨å£è¯­åŒ–è¡¨è¾¾\n   - æŠ€æœ¯æœ¯è¯­ï¼šä½¿ç”¨æ ‡å‡†åŒ–è¯‘æ³•\n5. è¾“å‡ºçº¯ç¿»è¯‘ç»“æœ\n\n## OutputFormat\nä»…è¿”å›ç¬¦åˆä»¥ä¸‹è¦æ±‚çš„ç¿»è¯‘æ–‡æœ¬ï¼š\n1. ä¸­æ–‡ä¹¦é¢è¯­è¡¨è¾¾\n2. ä¿ç•™åŸå§‹æ®µè½ç»“æ„\n3. æ—¶é—´æˆ³ä¿æŒ(MM:SS)æˆ–(HH:MM:SS)æ ¼å¼\n4. æ— ä»»ä½•é™„åŠ ç¬¦å·æˆ–è¯´æ˜\n4. å°½é‡åªè¦ä¸­æ–‡ï¼Œä¸è¦ä¸­è‹±æ–‡å¤¹æ‚ã€‚"},
                    {"role": "user", "content": batch}
                ],
                "stream": False,
                "max_tokens": 4000
            }
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} å‘é€APIè¯·æ±‚åˆ° {url}")
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} APIå“åº”çŠ¶æ€ç : {response.status_code}")
            response.raise_for_status()
            result = response.json()
            translated_content = result['choices'][0]['message']['content']

            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘å®Œæˆï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(translated_content)} å­—ç¬¦")
            print(f"ç¿»è¯‘å†…å®¹é¢„è§ˆ: {translated_content[:200]}...")
            return translated_content
        except Exception as e:
            print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return f"Error: {str(e)}"

    translated_results = {}
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(translate_batch, batch, i): i for i, batch in enumerate(batched_paragraphs)}
        for future in as_completed(futures):
            index = futures[future]
            result = future.result()
            if not result.startswith("Error:"):
                translated_results[index] = result

    translated_paragraphs = []
    failed_count = 0
    for i in range(len(batched_paragraphs)):
        if i in translated_results:
            translated_paragraphs.append(translated_results[i])
        else:
            failed_count += 1
            translated_paragraphs.append(f"ç¿»è¯‘å¤±è´¥çš„åˆ†æ®µ {i+1}")

    if failed_count > 0:
        print(f"è­¦å‘Šï¼š{failed_count} ä¸ªåˆ†æ®µç¿»è¯‘å¤±è´¥")

    final_output_file = os.path.splitext(vtt_file_path)[0] + "_translated.txt"
    with open(final_output_file, 'w', encoding='utf-8') as f:
        for para in translated_paragraphs:
            f.write(para + "\n\n")

    print(f"ç¿»è¯‘å®Œæˆï¼Œä¿å­˜åˆ°: {final_output_file}")
    return final_output_file

# TTS ç›¸å…³å‡½æ•° - ç§»åˆ°æ¨¡å—çº§åˆ«ä»¥æ”¯æŒå¤šè¿›ç¨‹
async def text_to_speech(text, output_file, voice="zh-CN-XiaoxiaoNeural", max_retries=5):
    """
    å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶
    æ·»åŠ é‡è¯•æœºåˆ¶å’Œå»¶è¿Ÿï¼Œå¤„ç†edge-tts APIçš„503é”™è¯¯
    """
    retry_count = 0
    base_delay = 1  # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
    while retry_count <= max_retries:
        try:
            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºè§„å¾‹
            if retry_count > 0:
                delay = base_delay * (2 ** (retry_count - 1)) + (random.random() * 0.5)
                print(f"ç¬¬{retry_count}æ¬¡é‡è¯•ï¼Œç­‰å¾…{delay:.2f}ç§’åç»§ç»­...")
                await asyncio.sleep(delay)
            communicate = edge_tts.Communicate(text, voice)
            await communicate.save(output_file)
            return  # æˆåŠŸåˆ™é€€å‡ºå¾ªç¯
        except Exception as e:
            error_msg = str(e).lower()
            retry_count += 1
            # æ£€æŸ¥æ˜¯å¦æ˜¯503é”™è¯¯æˆ–å…¶ä»–å¯é‡è¯•çš„é”™è¯¯
            if "503" in error_msg or "timeout" in error_msg or "connection" in error_msg:
                if retry_count <= max_retries:
                    print(f"é‡åˆ°APIé”™è¯¯: {e}ï¼Œå‡†å¤‡ç¬¬{retry_count}æ¬¡é‡è¯•...")
                else:
                    print(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œæ— æ³•å®Œæˆè½¬æ¢: {e}")
                    raise  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºå¼‚å¸¸
            else:
                # å…¶ä»–ç±»å‹çš„é”™è¯¯ç›´æ¥æŠ›å‡º
                print(f"é‡åˆ°éé‡è¯•ç±»å‹çš„é”™è¯¯: {e}")
                raise

def run_text_to_speech(text, output_file, voice="zh-CN-XiaoxiaoNeural", max_retries=5):
    """
    åœ¨å¤šè¿›ç¨‹ä¸­è¿è¡Œtext_to_speechçš„åŒ…è£…å‡½æ•°
    """
    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯å¹¶åœ¨å…¶ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(text_to_speech(text, output_file, voice, max_retries))
    finally:
        loop.close()

def process_segment(task):
    """
    å¤„ç†å•ä¸ªæ–‡æœ¬æ®µè½çš„å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹å¤„ç†
    """
    i, timestamp, txt, temp_dir, voice = task
    try:
        cleaned_timestamp = re.sub(r'[^\w\d]+', '_', timestamp)
        file_name = f"{cleaned_timestamp}.mp3"
        output_file = os.path.join(temp_dir, file_name)

        print(f"è¿›ç¨‹æ­£åœ¨å¤„ç†æ®µè½ {i+1}: {timestamp} - {txt[:30]}...")
        run_text_to_speech(txt, output_file, voice)

        time_ms = parse_timestamp(f"({timestamp})")
        return i, output_file, time_ms, None
    except Exception as e:
        return i, None, None, f"å¤„ç†æ®µè½ {i+1} æ—¶å‡ºé”™: {str(e)}"

def adjust_audio_speed(task):
    """
    è°ƒæ•´éŸ³é¢‘é€Ÿåº¦çš„å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹å¤„ç†
    """
    i, temp_output, target_duration, speed_factor = task
    temp_output_processed = temp_output + '.tmp.mp3'
    try:
        subprocess.run([
            'ffmpeg', '-y', '-i', temp_output,
            '-filter:a', f'atempo={speed_factor}',
            temp_output_processed
        ], check=True, capture_output=True)
        # Replace original file with processed one
        os.replace(temp_output_processed, temp_output)
        return i, temp_output, None  # è¿”å›å®é™…çš„æ–‡ä»¶è·¯å¾„
    except subprocess.CalledProcessError as e:
        # Clean up temporary file if it exists
        if os.path.exists(temp_output_processed):
            os.remove(temp_output_processed)
        return i, None, f"éŸ³é¢‘é€Ÿåº¦è°ƒæ•´å¤±è´¥ {i+1}: {e}"

def process_tts_with_speed_adjustment(txt_file_path, output_mp3_path, subtitles_dir):
    """å¤„ç†TTSè½¬æ¢å¹¶è¿›è¡ŒéŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»¥é¿å…é‡å """
    print("="*50, flush=True)
    print("å¼€å§‹TTSè½¬æ¢æµç¨‹", flush=True)
    print("="*50, flush=True)

    with open(txt_file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    print(f"txt_file_path: {txt_file_path}", flush=True)
    print(f"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(txt_file_path)}", flush=True)
    print(f"contenté•¿åº¦: {len(content)} å­—ç¬¦", flush=True)

    # ä½¿ç”¨ç¬”è®°æœ¬ä¸­çš„æ­£ç¡®æ­£åˆ™è¡¨è¾¾å¼
    pattern = r'[\\(ï¼ˆ](\d{1,2})?:?(\d{1,3}):(\d{1,2})(?:\.(\d{1,3}))?[\\)ï¼‰](.+?)(?=[\\(ï¼ˆ](?:\d{1,2})?:?(\d{1,3}):(\d{1,2})(?:\.(\d{1,3}))?[\\)ï¼‰]|$)'
    matches = list(re.finditer(pattern, content, re.DOTALL))
    print(f"åŒ¹é…åˆ°çš„segmentsæ•°é‡: {len(matches)}", flush=True)

    segments = []
    for match in matches:
        timestamp_string = match.group(0)
        content_text = match.group(5).strip()
        if content_text:
            # æå–æ—¶é—´æˆ³éƒ¨åˆ†
            timestamp_match = re.match(r'[\\(ï¼ˆ](.+?)[\\)ï¼‰]', timestamp_string)
            if timestamp_match:
                timestamp = timestamp_match.group(1)
                segments.append((timestamp, content_text))

    print(f"è§£æå‡ºçš„segmentsæ•°é‡: {len(segments)}", flush=True)
    if segments:
        print(f"å‰3ä¸ªsegments:", flush=True)
        for i, (ts, txt) in enumerate(segments[:3]):
            print(f"  {i+1}: ({ts}) {txt[:50]}...", flush=True)

    temp_dir = os.path.dirname(output_mp3_path) if os.path.dirname(output_mp3_path) else TEMP_DIR

    tasks = []
    for i, (timestamp, txt) in enumerate(segments):
        cleaned_timestamp = re.sub(r'[^\w\d]+', '_', timestamp)
        file_name = f"{cleaned_timestamp}.mp3"
        output_file = os.path.join(temp_dir, file_name)
        tasks.append((i, timestamp, txt, temp_dir, SELECTED_VOICE))

    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_segment, task) for task in tasks]

        audio_files = [None] * len(tasks)

        for future in as_completed(futures):
            index, output_file, time_ms, error = future.result()
            if error:
                print(f"è­¦å‘Š: {error}")
            if output_file and os.path.exists(output_file):
                audio_files[index] = (output_file, time_ms)

        audio_files = [af for af in audio_files if af is not None]

    print(f"è°ƒè¯•ä¿¡æ¯ï¼šaudio_files æ•°é‡: {len(audio_files)}")
    if audio_files:
        print(f"è°ƒè¯•ä¿¡æ¯ï¼šaudio_files[0] ç»“æ„: {audio_files[0]}")

    audio_files.sort(key=lambda x: x[1])

    if audio_files:
        # å¯¼å…¥å¿…è¦çš„åº“
        from pydub import AudioSegment
        import numpy as np
        from multiprocessing import shared_memory

        # éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»¥é¿å…é‡å  (åœ¨æ··éŸ³ä¹‹å‰è¿›è¡Œ)
        print("å¼€å§‹éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ï¼Œsegmentsæ•°é‡:", len(segments))
        print("segmentsç¤ºä¾‹:", segments[:2] if segments else 'ç©º')

        processed_audio_segments = []
        for i, (audio_file_path, time_ms) in enumerate(audio_files):
            audio = AudioSegment.from_file(audio_file_path)
            processed_audio_segments.append((audio_file_path, time_ms, audio))

        # è®¡ç®—éœ€è¦è°ƒæ•´é€Ÿåº¦çš„éŸ³é¢‘ç‰‡æ®µ
        speed_adjust_tasks_list = []
        print(f"å¼€å§‹è®¡ç®—é€Ÿåº¦è°ƒæ•´ä»»åŠ¡ï¼Œç‰‡æ®µæ€»æ•°: {len(processed_audio_segments)}")

        for i, (audio_file_path, time_ms, audio) in enumerate(processed_audio_segments[:-1]):
            current_len = len(audio)
            end_time = time_ms + current_len

            # è®¡ç®—ä¸‹ä¸€ä¸ªç‰‡æ®µçš„å¼€å§‹æ—¶é—´
            if i + 1 < len(processed_audio_segments):
                next_start = processed_audio_segments[i+1][1]
                if end_time > next_start + 100:  # å¦‚æœé‡å è¶…è¿‡100ms
                    target = next_start - time_ms - 50  # ç•™50msç¼“å†²
                    if target > 100:  # ç›®æ ‡æ—¶é•¿è‡³å°‘100ms
                        factor = min(current_len / target, 2.0)  # æœ€å¤šåŠ é€Ÿ2å€
                        print(f"ç‰‡æ®µ{i}: å½“å‰æ—¶é—´={time_ms}ms, ä¸‹ä¸€ä¸ªæ—¶é—´={next_start}ms, ç›®æ ‡æ—¶é•¿={target}ms, å®é™…æ—¶é•¿={current_len}ms")
                        print(f"  éœ€è¦åŠ é€Ÿ: å› å­={factor:.2f}")
                        if factor > 1.0:  # åªæœ‰éœ€è¦åŠ é€Ÿæ—¶æ‰è°ƒæ•´
                            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºé€Ÿåº¦è°ƒæ•´
                            temp_speed_file = audio_file_path.replace('.mp3', '_speed.mp3')
                            audio.export(temp_speed_file, format="mp3")
                            speed_adjust_tasks_list.append((i, temp_speed_file, target, factor))

        print(f"éœ€è¦è°ƒæ•´é€Ÿåº¦çš„éŸ³é¢‘ç‰‡æ®µæ•°é‡: {len(speed_adjust_tasks_list)}")

        # æ‰§è¡Œé€Ÿåº¦è°ƒæ•´
        if speed_adjust_tasks_list:
            print(f"å¼€å§‹å¤„ç† {len(speed_adjust_tasks_list)} ä¸ªéŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»»åŠ¡...")

            with ProcessPoolExecutor(max_workers=8) as executor:
                futures = [executor.submit(adjust_audio_speed, task) for task in speed_adjust_tasks_list]

                for future in as_completed(futures):
                    try:
                        result = future.result()
                        if result and len(result) >= 3:
                            i, adjusted_file_path, error = result
                            if error:
                                print(f"é€Ÿåº¦è°ƒæ•´å¤±è´¥ {i}: {error}")
                                continue
                            if adjusted_file_path and os.path.exists(adjusted_file_path):
                                # éªŒè¯è°ƒæ•´åçš„æ–‡ä»¶ç¡®å®å­˜åœ¨
                                print(f"é€Ÿåº¦è°ƒæ•´æˆåŠŸ {i}: {adjusted_file_path}")
                    except Exception as e:
                        print(f"éŸ³é¢‘é€Ÿåº¦è°ƒæ•´ä»»åŠ¡å¤±è´¥: {e}")

        # ç°åœ¨è¿›è¡Œæœ€ç»ˆæ··éŸ³ - ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘æ–‡ä»¶
        print(f"å¼€å§‹æ··éŸ³ {len(processed_audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")

        # å¯¼å…¥å¿…è¦çš„åº“
        from pydub import AudioSegment
        import numpy as np
        from multiprocessing import shared_memory

        SR = 24000
        N_CH = 1
        WIDTH = 2

        def to_int16_samples(audio_segment):
            audio = audio_segment.set_frame_rate(SR).set_channels(N_CH).set_sample_width(WIDTH)
            return np.frombuffer(audio_segment.raw_data, dtype=np.int16)

        # ä¸ºæ··éŸ³å‡†å¤‡éŸ³é¢‘æ•°æ® - æ£€æŸ¥æ˜¯å¦æœ‰è°ƒæ•´åçš„æ–‡ä»¶
        final_audio_segments = []
        for audio_file_path, time_ms, original_audio in processed_audio_segments:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„è°ƒæ•´åæ–‡ä»¶
            adjusted_file = audio_file_path.replace('.mp3', '_speed.mp3')
            if os.path.exists(adjusted_file):
                # ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘æ–‡ä»¶
                try:
                    adjusted_audio = AudioSegment.from_file(adjusted_file)
                    final_audio_segments.append((adjusted_file, time_ms, adjusted_audio))
                    print(f"ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘: {os.path.basename(adjusted_file)}, æ—¶é•¿={len(adjusted_audio)}ms")
                except Exception as e:
                    print(f"åŠ è½½è°ƒæ•´åçš„éŸ³é¢‘å¤±è´¥ {adjusted_file}: {e}, ä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    final_audio_segments.append((audio_file_path, time_ms, original_audio))
            else:
                # ä½¿ç”¨åŸå§‹éŸ³é¢‘
                final_audio_segments.append((audio_file_path, time_ms, original_audio))
                print(f"ä½¿ç”¨åŸå§‹éŸ³é¢‘: {os.path.basename(audio_file_path)}, æ—¶é•¿={len(original_audio)}ms")

        print(f"æœ€ç»ˆéŸ³é¢‘æ®µæ•°: {len(final_audio_segments)}")

        # è®¡ç®—æ€»æ—¶é•¿
        last_path, last_ms, last_audio = final_audio_segments[-1]
        print(f"æœ€åç‰‡æ®µ: {last_path}, æ—¶é—´={last_ms}ms, æ—¶é•¿={len(last_audio)}ms")
        total_ms = last_ms + len(last_audio) + 1000
        total_samples = int(total_ms * SR / 1000)

        # åˆ›å»ºå…±äº«å†…å­˜ç¼“å†²åŒº
        shm = shared_memory.SharedMemory(create=True, size=total_samples * N_CH * 4)
        buf = np.ndarray((total_samples * N_CH,), dtype=np.float32, buffer=shm.buf)
        buf[:] = 0.0

        # æ··åˆæ‰€æœ‰éŸ³é¢‘æ®µ
        for audio_file_path, start_ms, audio_segment in final_audio_segments:
            samples = to_int16_samples(audio_segment).astype(np.float32)
            start_sample = int(start_ms * SR / 1000)
            end_sample = start_sample + len(samples)
            if end_sample > len(buf):
                end_sample = len(buf)  # é˜²æ­¢è¶Šç•Œ
            buf[start_sample:end_sample] += samples
            print(f"æ··éŸ³ç‰‡æ®µ: {os.path.basename(audio_file_path)}, èµ·å§‹={start_sample}, ç»“æŸ={end_sample}")

        np.clip(buf, -32768, 32767, out=buf)
        out_bytes = buf.astype(np.int16).tobytes()
        shm.close()
        shm.unlink()

        final_audio = AudioSegment(data=out_bytes, sample_width=WIDTH, frame_rate=SR, channels=N_CH)
        final_audio.export(output_mp3_path, format="mp3")
        print(f"æœ€ç»ˆéŸ³é¢‘å·²ä¿å­˜: {output_mp3_path}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for fp, _ in audio_files:
            if os.path.exists(fp):
                os.remove(fp)

        # æ¸…ç†è°ƒæ•´åçš„ä¸´æ—¶æ–‡ä»¶
        for audio_file_path, _, _ in processed_audio_segments:
            speed_file = audio_file_path.replace('.mp3', '_speed.mp3')
            if os.path.exists(speed_file):
                os.remove(speed_file)
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {os.path.basename(speed_file)}")

        return output_mp3_path

    return None

def parse_timestamp(timestamp):
    match = re.match(r'[\(ï¼ˆ](?:(\d{1,2}):)?(\d{1,3}):(\d{1,2})(?:\.(\d{1,3}))?[\)ï¼‰]', timestamp)
    if match:
        hours, minutes, seconds, milliseconds = match.groups()
        total_ms = 0
        if hours:
            total_ms += int(hours) * 3600 * 1000
        total_ms += int(minutes) * 60 * 1000
        total_ms += int(seconds) * 1000
        if milliseconds:
            total_ms += int(milliseconds.ljust(3, '0'))
        return total_ms
    return 0

st.set_page_config(
    page_title="YouTubeè½¬Bç«™æ¬è¿å·¥å…·",
    page_icon="ğŸ¥",
    layout="wide"
)

st.title("YouTubeè½¬Bç«™æ¬è¿ä¸€æ¡é¾™")
st.markdown("---")

st.sidebar.header("âš™ï¸ é…ç½®")

API_URL = st.sidebar.text_input("API URL", value=env_config.get("API_URL", "https://api.siliconflow.cn/v1/chat/completions"), help="ç¿»è¯‘APIçš„URL", key="api_url")
API_KEY = st.sidebar.text_input("API Key", type="password", value=env_config.get("API_KEY", ""), help="ç¿»è¯‘APIçš„Keyï¼ˆå°†åœ¨è¿è¡Œæ—¶ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰", key="api_key")
MODEL_NAME = st.sidebar.text_input("æ¨¡å‹åç§°", value=env_config.get("MODEL_NAME", "THUDM/GLM-4-9B-0414"), help="ç¿»è¯‘ä½¿ç”¨çš„æ¨¡å‹åç§°", key="model_name")

BILI_SESSDATA = st.sidebar.text_area("Bç«™Cookie", value=env_config.get("BILI_SESSDATA", ""), help="Bç«™çš„sessdataï¼ˆç”¨äºä¸Šä¼ ï¼‰", height=100, key="bili_sessdata")
BILI_ACCESS_KEY_ID = st.sidebar.text_input("Bç«™Access Key ID", value=env_config.get("BILI_ACCESS_KEY_ID", ""), help="Bç«™çš„access_key_id", key="bili_access_key_id")
BILI_ACCESS_KEY_SECRET = st.sidebar.text_input("Bç«™Access Key Secret", type="password", value=env_config.get("BILI_ACCESS_KEY_SECRET", ""), help="Bç«™çš„access_key_secret", key="bili_access_key_secret")

YT_COOKIES = st.sidebar.text_area("YouTube Cookies (å¯é€‰)", value=env_config.get("YT_COOKIES", ""), help="YouTube cookiesï¼ˆç”¨äºè®¿é—®éœ€è¦ç™»å½•çš„è§†é¢‘ï¼‰", height=100, key="yt_cookies")

VOICE_CHOICES = ["zh-CN-XiaoxiaoNeural", "zh-CN-YunjianNeural", "zh-CN-YunxiNeural"]
SELECTED_VOICE = st.sidebar.selectbox("TTSè¯­éŸ³è§’è‰²", options=VOICE_CHOICES, index=1, key="selected_voice")

MAX_WORKERS = st.sidebar.slider("ç¿»è¯‘å¹¶å‘æ•°", min_value=1, max_value=20, value=10, help="åŒæ—¶ç¿»è¯‘çš„æ®µè½æ•°é‡")
SEGMENT_SIZE = st.sidebar.slider("ç¿»è¯‘åˆ†æ®µå¤§å°", min_value=1, max_value=20, value=11, help="æ¯æ¬¡ç¿»è¯‘åŒ…å«çš„æ®µè½æ•°é‡")

st.markdown("---")

TEMP_DIR = os.path.join(os.getcwd(), "temp_storage")
if not os.path.exists(TEMP_DIR):
    try:
        os.makedirs(TEMP_DIR, exist_ok=True)
    except Exception as e:
        # å¦‚æœå½“å‰ç›®å½•ä¸å¯å†™ï¼Œå†é€€å›åˆ°ç³»ç»Ÿä¸´æ—¶ç›®å½•
        TEMP_DIR = os.path.join(tempfile.gettempdir(), "yt_video_trans_temp")
        os.makedirs(TEMP_DIR, exist_ok=True)

temp_dir = None

tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "0ï¸ğŸš€ ä¸€é”®å·¥ä½œæµ",
        "1ï¸â¬‡ï¸ ä¸‹è½½å­—å¹•", 
        "2ï¸âš™ï¸ ç¿»è¯‘å­—å¹•", 
        "3ï¸ğŸ—£ï¸ è½¬è¯­éŸ³", 
        "4ï¸ğŸ¬ï¸ ä¸‹è½½è§†é¢‘", 
        "5ï¸ğŸ–¼ï¸ å¤„ç†å°é¢", 
        "6ï¸âœ‚ï¸ è§†é¢‘å‰ªè¾‘", 
        "7ï¸ğŸ“¤ï¸ ä¸Šä¼ Bç«™"
    ])

with tab0:
    st.markdown("""
    <style>
    .workflow-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
    }
    .step-card {
        background: rgba(255,255,255,0.1);
        border: 1px solid rgba(255,255,255,0.2);
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .step-success {
        background: rgba(40,167,69,0.3);
        border-color: #28a745;
    }
    .step-error {
        background: rgba(220,53,69,0.3);
        border-color: #dc3545;
    }
    .step-running {
        background: rgba(255,193,7,0.3);
        border-color: #ffc107;
    }
    </style>
    <div class="workflow-container">
        <h1 style="text-align:center; margin-bottom:1rem;">ğŸš€ ä¸€é”®å·¥ä½œæµ</h1>
        <p style="text-align:center; opacity:0.9;">å…¨è‡ªåŠ¨å®Œæˆä»YouTubeåˆ°Bç«™çš„è§†é¢‘æ¬è¿</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        workflow_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="workflow_url")
    with col2:
        auto_upload = st.checkbox("è‡ªåŠ¨ä¸Šä¼ åˆ°Bç«™", value=True, help="å‹¾é€‰åå®Œæˆæ‰€æœ‰æ­¥éª¤ä¼šè‡ªåŠ¨ä¸Šä¼ ï¼Œå¦åˆ™åªå¤„ç†åˆ°å°é¢")
    
    st.markdown("---")
    
    progress_container = st.container()
    
    if st.button("ğŸš€ å¼€å§‹ä¸€é”®å·¥ä½œæµ", type="primary", use_container_width=True):
        if not workflow_url:
            st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
        else:
            # æ¸…ç©ºtempç›®å½•
            clear_temp_directory()

            status_container = st.container()
            
            steps_status = {
                "ä¸‹è½½å­—å¹•": {"status": "pending", "message": ""},
                "ç¿»è¯‘æ ‡é¢˜": {"status": "pending", "message": ""},
                "ç¿»è¯‘å­—å¹•": {"status": "pending", "message": ""},
                "è½¬è¯­éŸ³": {"status": "pending", "message": ""},
                "ä¸‹è½½è§†é¢‘": {"status": "pending", "message": ""},
                "å¤„ç†å°é¢": {"status": "pending", "message": ""},
                "ä¸Šä¼ Bç«™": {"status": "pending", "message": ""}
            }
            
            def update_step_status(step_name, status, message=""):
                steps_status[step_name]["status"] = status
                steps_status[step_name]["message"] = message
                
                status_dict = {
                    "pending": "â³",
                    "running": "ğŸ”„",
                    "success": "âœ…",
                    "error": "âŒ"
                }
                
                step_class = {
                    "pending": "step-card",
                    "running": "step-card step-running",
                    "success": "step-card step-success",
                    "error": "step-card step-error"
                }
                
                return status_dict[status], step_class[status]
            
            def retry_with_backoff(func, max_retries=3, step_name="æ“ä½œ"):
                for attempt in range(max_retries):
                    try:
                        return func()
                    except Exception as e:
                        if attempt < max_retries - 1:
                            delay = 2 ** attempt
                            current_attempt = attempt + 1
                            retry_msg = f"{step_name}å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯• ({current_attempt}/{max_retries}): {str(e)}"
                            st.warning(retry_msg)
                            time.sleep(delay)
                        else:
                            raise e
            
            try:
                subtitles_dir = os.path.join(TEMP_DIR, "subtitles")
                os.makedirs(subtitles_dir, exist_ok=True)
                
                with status_container:
                    st.markdown("## ğŸ“‹ å·¥ä½œæµè¿›åº¦")
                    
                    icon1, class1 = update_step_status("ä¸‹è½½å­—å¹•", "running")
                    st.markdown(f"""
                    <div class="{class1}">
                        <strong>{icon1} æ­¥éª¤1: ä¸‹è½½å­—å¹•</strong><br/>
                        <span id="msg1"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step1_download_subtitles():
                        cookies_file_path = None
                        if YT_COOKIES.strip():
                            cookies_file_path = os.path.join(TEMP_DIR, "youtube_cookies.txt")
                            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                                f.write(YT_COOKIES.strip())
                        
                        ydl_opts = {
                            'writeautomaticsub': True,
                            'skip_download': True,
                            'subtitleslangs': ['en'],
                            'quiet': True,
                            'outtmpl': os.path.join(subtitles_dir, '%(title)s.%(ext)s')
                        }
                        
                        if cookies_file_path:
                            ydl_opts['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                            ydl.download([workflow_url])
                        
                        vtt_files = list(Path(subtitles_dir).glob("*.vtt"))
                        if vtt_files:
                            original_file = vtt_files[0]
                            new_file = os.path.join(subtitles_dir, "word_level.vtt")
                            os.rename(original_file, new_file)
                            return new_file
                        return None
                    
                    vtt_file_path = retry_with_backoff(step1_download_subtitles, max_retries=3, step_name="ä¸‹è½½å­—å¹•")
                    
                    icon1, class1 = update_step_status("ä¸‹è½½å­—å¹•", "success", f"æˆåŠŸ: {vtt_file_path}")
                    st.markdown(f"""
                    <div class="{class1}">
                        <strong>{icon1} æ­¥éª¤1: ä¸‹è½½å­—å¹•</strong><br/>
                        {vtt_file_path}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    icon2, class2 = update_step_status("ç¿»è¯‘æ ‡é¢˜", "running")
                    st.markdown(f"""
                    <div class="{class2}">
                        <strong>{icon2} æ­¥éª¤2: ç¿»è¯‘æ ‡é¢˜</strong><br/>
                        <span id="msg2"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step2_translate_title():
                        ydl_info_opts = {
                            'skip_download': True,
                            'quiet': True,
                        }
                        
                        cookies_file_path = None
                        if YT_COOKIES.strip():
                            cookies_file_path = os.path.join(TEMP_DIR, "youtube_cookies.txt")
                        
                        if cookies_file_path and os.path.exists(cookies_file_path):
                            ydl_info_opts['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
                            info_dict = ydl.extract_info(workflow_url, download=False)
                            original_title = info_dict.get('title', '')
                        
                        if not original_title:
                            raise Exception("æ— æ³•è·å–è§†é¢‘æ ‡é¢˜")
                        
                        SYSTEM_PROMPT = """ä½ æ˜¯çˆ†æ¬¾è§†é¢‘upä¸»ï¼Œå°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆå¸å¼•çœ¼çƒçš„çˆ†æ¬¾è§†é¢‘ä¸­æ–‡æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"""
                        
                        payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": SYSTEM_PROMPT},
                                {"role": "user", "content": original_title}
                            ]
                        }
                        headers = {
                            "Authorization": f"Bearer {API_KEY}",
                            "Content-Type": "application/json"
                        }
                        
                        response = requests.post(API_URL, json=payload, headers=headers, timeout=60)
                        response_data = response.json()
                        
                        translated_title_with_markdown = response_data['choices'][0]['message']['content']
                        translated_title = translated_title_with_markdown.replace('**', '').strip()
                        
                        TAGS_PROMPT = f"""æ ¹æ®ä»¥ä¸‹è§†é¢‘æ ‡é¢˜ï¼Œç”Ÿæˆ5-8ä¸ªBç«™è§†é¢‘æ ‡ç­¾ï¼ˆåªè¾“å‡ºæ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼‰ï¼š
æ ‡é¢˜ï¼š{translated_title}
ç¤ºä¾‹æ ‡ç­¾ï¼šç§‘æŠ€,äººå·¥æ™ºèƒ½,AI,æœºå™¨å­¦ä¹ ,æœªæ¥
åªè¾“å‡ºæ ‡ç­¾ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
                        
                        tags_payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Bç«™è¿è¥åŠ©æ‰‹"},
                                {"role": "user", "content": TAGS_PROMPT}
                            ]
                        }
                        
                        tags_response = requests.post(API_URL, json=tags_payload, headers=headers, timeout=60)
                        tags_data = tags_response.json()
                        
                        tags_content = tags_data['choices'][0]['message']['content']
                        tags_list = [t.strip() for t in tags_content.replace('ï¼Œ', ',').split(',') if t.strip()]
                        # é™åˆ¶tagsæ•°é‡ä¸è¶…è¿‡10ä¸ª
                        tags_list = tags_list[:10]

                        upload_config_file = os.path.join(subtitles_dir, "upload_config.pkl")
                        upload_data = {
                            'title_desc': f'(ä¸­é…){translated_title}',
                            'tags': tags_list
                        }
                        
                        with open(upload_config_file, 'wb') as f:
                            pickle.dump(upload_data, f)
                        
                        return translated_title, tags_list
                    
                    translated_title, tags_list = retry_with_backoff(step2_translate_title, max_retries=3, step_name="ç¿»è¯‘æ ‡é¢˜")
                    
                    icon2, class2 = update_step_status("ç¿»è¯‘æ ‡é¢˜", "success", f"æ ‡é¢˜: {translated_title}")
                    st.markdown(f"""
                    <div class="{class2}">
                        <strong>{icon2} æ­¥éª¤2: ç¿»è¯‘æ ‡é¢˜</strong><br/>
                        {translated_title}<br/>
                        æ ‡ç­¾: {', '.join(tags_list)}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    icon3, class3 = update_step_status("ç¿»è¯‘å­—å¹•", "running")
                    st.markdown(f"""
                    <div class="{class3}">
                        <strong>{icon3} æ­¥éª¤3: ç¿»è¯‘å­—å¹•</strong><br/>
                        <span id="msg3"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step3_translate_subtitles():
                        # ç›´æ¥è°ƒç”¨å•æ­¥æ‰§è¡Œçš„ç¿»è¯‘å­—å¹•é€»è¾‘
                        return translate_subtitles_from_vtt(vtt_file_path)
                    
                    txt_file_path = retry_with_backoff(step3_translate_subtitles, max_retries=3, step_name="ç¿»è¯‘å­—å¹•")
                    
                    icon3, class3 = update_step_status("ç¿»è¯‘å­—å¹•", "success", f"ä¿å­˜åˆ°: {txt_file_path}")
                    st.markdown(f"""
                    <div class="{class3}">
                        <strong>{icon3} æ­¥éª¤3: ç¿»è¯‘å­—å¹•</strong><br/>
                        {txt_file_path}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    icon4, class4 = update_step_status("è½¬è¯­éŸ³", "running")
                    st.markdown(f"""
                    <div class="{class4}">
                        <strong>{icon4} æ­¥éª¤4: è½¬è¯­éŸ³</strong><br/>
                        <span id="msg4"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step4_tts():
                        output_mp3 = os.path.join(subtitles_dir, os.path.splitext(os.path.basename(vtt_file_path))[0] + "_translated.mp3")
                        result = process_tts_with_speed_adjustment(txt_file_path, output_mp3, subtitles_dir)
                        return result
                    
                    mp3_file_path = retry_with_backoff(step4_tts, max_retries=3, step_name="è½¬è¯­éŸ³")
                    
                    icon4, class4 = update_step_status("è½¬è¯­éŸ³", "success", f"ä¿å­˜åˆ°: {mp3_file_path}")
                    st.markdown(f"""
                    <div class="{class4}">
                        <strong>{icon4} æ­¥éª¤4: è½¬è¯­éŸ³</strong><br/>
                        {mp3_file_path}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    icon5, class5 = update_step_status("ä¸‹è½½è§†é¢‘", "running")
                    st.markdown(f"""
                    <div class="{class5}">
                        <strong>{icon5} æ­¥éª¤5: ä¸‹è½½è§†é¢‘</strong><br/>
                        <span id="msg5"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step5_download_video():
                        downloaded_video_base_name = os.path.join(TEMP_DIR, "subtitles", "downloaded_video")
                        
                        ydl_opts_video_only = {
                            'format': 'best',
                            'outtmpl': f'{downloaded_video_base_name}.%(ext)s',
                            'noplaylist': True,
                        }
                        
                        cookies_file_path = None
                        if YT_COOKIES.strip():
                            cookies_file_path = os.path.join(TEMP_DIR, "youtube_cookies.txt")
                        
                        if cookies_file_path:
                            ydl_opts_video_only['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_video_only) as ydl:
                            ydl.extract_info(workflow_url, download=True)
                        
                        downloaded_files = glob.glob(f"{downloaded_video_base_name}.*")
                        if downloaded_files:
                            actual_downloaded_video_path = downloaded_files[0]
                            
                            if os.path.exists(mp3_file_path):
                                final_video_path = os.path.splitext(mp3_file_path)[0] + ".mp4"
                                subprocess.run(['ffmpeg', '-y', '-i', actual_downloaded_video_path, '-i', mp3_file_path,
                                                    '-c:v', 'copy', '-c:a', 'aac', '-map', '0:v:0', '-map', '1:a:0',
                                                    final_video_path], check=True, capture_output=True, text=True)
                                
                                if os.path.exists(actual_downloaded_video_path):
                                    os.remove(actual_downloaded_video_path)
                                
                                return final_video_path
                        
                        raise FileNotFoundError("è§†é¢‘ä¸‹è½½å¤±è´¥")
                    
                    final_video_path = retry_with_backoff(step5_download_video, max_retries=3, step_name="ä¸‹è½½è§†é¢‘")
                    
                    icon5, class5 = update_step_status("ä¸‹è½½è§†é¢‘", "success", f"ä¿å­˜åˆ°: {final_video_path}")
                    st.markdown(f"""
                    <div class="{class5}">
                        <strong>{icon5} æ­¥éª¤5: ä¸‹è½½è§†é¢‘</strong><br/>
                        {final_video_path}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    icon6, class6 = update_step_status("å¤„ç†å°é¢", "running")
                    st.markdown(f"""
                    <div class="{class6}">
                        <strong>{icon6} æ­¥éª¤6: å¤„ç†å°é¢</strong><br/>
                        <span id="msg6"></span>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    def step6_process_cover():
                        ydl_opts_thumbnail = {
                            'skip_download': True,
                            'writethumbnail': True,
                            'outtmpl': os.path.join(TEMP_DIR, "subtitles", 'cover.%(ext)s'),
                            'noplaylist': True,
                        }
                        
                        cookies_file_path = None
                        if YT_COOKIES.strip():
                            cookies_file_path = os.path.join(TEMP_DIR, "youtube_cookies.txt")
                        
                        if cookies_file_path:
                            ydl_opts_thumbnail['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_thumbnail) as ydl:
                            ydl.extract_info(workflow_url, download=True)
                        
                        input_path = os.path.join(TEMP_DIR, "subtitles", "cover.webp")
                        output_path = os.path.join(TEMP_DIR, "subtitles", "cover.jpeg")
                        
                        if not os.path.exists(input_path):
                            input_files = list(Path(os.path.join(TEMP_DIR, "subtitles")).glob("cover.*"))
                            if input_files:
                                input_path = input_files[0]
                        
                        quality = 90
                        with Image.open(input_path) as img:
                            if img.mode != 'RGB':
                                img = img.convert('RGB')
                            img.save(output_path, 'jpeg', quality=quality)

                        current_size_kb = os.path.getsize(output_path) / 1024
                        while current_size_kb > 50 and quality > 4:
                            quality -= 5
                            img.save(output_path, 'jpeg', quality=quality)
                            current_size_kb = os.path.getsize(output_path) / 1024
                            print(f"å½“å‰å¤§å°: {current_size_kb:.2f} KB, è´¨é‡: {quality}")
                        
                        return output_path
                    
                    cover_file_path = retry_with_backoff(step6_process_cover, max_retries=3, step_name="å¤„ç†å°é¢")
                    
                    icon6, class6 = update_step_status("å¤„ç†å°é¢", "success", f"ä¿å­˜åˆ°: {cover_file_path}")
                    st.markdown(f"""
                    <div class="{class6}">
                        <strong>{icon6} æ­¥éª¤6: å¤„ç†å°é¢</strong><br/>
                        {cover_file_path}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.success("ğŸ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²å‡†å¤‡å¥½")
                    
                    st.markdown("---")
                    st.markdown("## ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶")
                    st.markdown(f"""
                    - å­—å¹•: {os.path.join(TEMP_DIR, 'subtitles', 'word_level.vtt')}
                    - ç¿»è¯‘æ–‡æœ¬: {txt_file_path}
                    - é…éŸ³: {mp3_file_path}
                    - æœ€ç»ˆè§†é¢‘: {final_video_path}
                    - å°é¢: {cover_file_path}
                    """)
                    
                    if auto_upload:
                        icon7, class7 = update_step_status("ä¸Šä¼ Bç«™", "running")
                        st.markdown(f"""
                        <div class="{class7}">
                            <strong>{icon7} æ­¥éª¤7: ä¸Šä¼ Bç«™</strong><br/>
                            <span id="msg7"></span>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        def step7_upload():
                            credential = Credential(
                                sessdata=BILI_SESSDATA,
                                bili_jct="bcd4ba0d9ab8a7b95485798ed8097d26"
                            )
                            
                            vu_meta = VideoMeta(
                                tid=130,
                                title=translated_title,
                                tags=tags_list,
                                desc=translated_title,
                                cover=cover_file_path,
                                no_reprint=True
                            )
                            
                            async def main_upload():
                                page = VideoUploaderPage(
                                    path=final_video_path,
                                    title=translated_title,
                                    description=translated_title,
                                )
                                
                                uploader = video_uploader.VideoUploader([page], vu_meta, credential, line=video_uploader.Lines.QN)
                                
                                @uploader.on("__ALL__")
                                async def ev(data):
                                    pass
                                
                                await uploader.start()
                            
                            asyncio.run(main_upload())
                            return True
                        
                        retry_with_backoff(step7_upload, max_retries=3, step_name="ä¸Šä¼ Bç«™")
                        
                        icon7, class7 = update_step_status("ä¸Šä¼ Bç«™", "success")
                        st.markdown(f"""
                        <div class="{class7}">
                            <strong>{icon7} æ­¥éª¤7: ä¸Šä¼ Bç«™</strong><br/>
                            ä¸Šä¼ æˆåŠŸï¼
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.success("ğŸ‰ ä¸Šä¼ æˆåŠŸï¼è§†é¢‘å·²å‘å¸ƒåˆ°Bç«™ï¼")
                    else:
                        st.info("ğŸ’¡ å¦‚éœ€ä¸Šä¼ Bç«™ï¼Œè¯·åœ¨å·¦ä¾§å‹¾é€‰'è‡ªåŠ¨ä¸Šä¼ åˆ°Bç«™'åé‡æ–°è¿è¡Œå·¥ä½œæµ")
            
            except Exception as e:
                import traceback
                st.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
                st.markdown(f"""
                <div class="step-card step-error">
                    <strong>é”™è¯¯è¯¦æƒ…:</strong><br/>
                    {traceback.format_exc()}
                </div>
                """, unsafe_allow_html=True)

with tab1:
    st.header("1ï¸â¬‡ï¸ ä¸‹è½½YouTubeå­—å¹•")
    youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="youtube_url_tab1")
    
    if st.button("ä¸‹è½½å­—å¹•", type="primary", key="download_subtitles_btn"):
        if not youtube_url:
            st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
        else:
            # æ¸…ç©ºtempç›®å½•
            clear_temp_directory()

            with st.spinner("æ­£åœ¨ä¸‹è½½å­—å¹•..."):
                temp_dir = TEMP_DIR
                try:
                    subtitles_dir = os.path.join(temp_dir, "subtitles")
                    os.makedirs(subtitles_dir, exist_ok=True)
                    
                    cookies_file_path = None
                    if YT_COOKIES.strip():
                        cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
                        with open(cookies_file_path, 'w', encoding='utf-8') as f:
                            f.write(YT_COOKIES.strip())
                    
                    ydl_opts = {
                        'writeautomaticsub': True,
                        'skip_download': True,
                        'subtitleslangs': ['en'],
                        'quiet': False,
                        'outtmpl': os.path.join(subtitles_dir, '%(title)s.%(ext)s')
                    }
                    
                    if cookies_file_path:
                        ydl_opts['cookiefile'] = cookies_file_path
                    
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        ydl.download([youtube_url])
                    
                    vtt_files = list(Path(subtitles_dir).glob("*.vtt"))
                    if vtt_files:
                        original_file = vtt_files[0]
                        new_file = os.path.join(subtitles_dir, "word_level.vtt")
                        os.rename(original_file, new_file)
                        st.success(f"å­—å¹•ä¸‹è½½æˆåŠŸï¼")
                        st.info(f"æ–‡ä»¶ä½ç½®: {new_file}")
                    else:
                        st.error("æœªæ‰¾åˆ°VTTå­—å¹•æ–‡ä»¶")
                        
                    st.markdown("---")
                    st.info("æ­£åœ¨è·å–å¹¶ç¿»è¯‘è§†é¢‘æ ‡é¢˜...")
                    
                    ydl_info_opts = {
                        'skip_download': True,
                        'quiet': True,
                    }
                    if cookies_file_path:
                        ydl_info_opts['cookiefile'] = cookies_file_path
                    
                    with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
                        info_dict = ydl.extract_info(youtube_url, download=False)
                        original_title = info_dict.get('title', '')
                    
                    if original_title:
                        st.text(f"åŸå§‹æ ‡é¢˜: {original_title}")
                        
                        SYSTEM_PROMPT = """ä½ æ˜¯çˆ†æ¬¾è§†é¢‘upä¸»ï¼Œå°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆå¸å¼•çœ¼çƒçš„çˆ†æ¬¾è§†é¢‘ä¸­æ–‡æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"""
                        
                        import requests
                        payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": SYSTEM_PROMPT},
                                {"role": "user", "content": original_title}
                            ]
                        }
                        headers = {
                            "Authorization": f"Bearer {API_KEY}",
                            "Content-Type": "application/json"
                        }
                        
                        response = requests.post(API_URL, json=payload, headers=headers, timeout=60)
                        response_data = response.json()
                        
                        translated_title_with_markdown = response_data['choices'][0]['message']['content']
                        translated_title = translated_title_with_markdown.replace('**', '').strip()
                        
                        st.text(f"ç¿»è¯‘æ ‡é¢˜: {translated_title}")
                        
                        TAGS_PROMPT = f"""æ ¹æ®ä»¥ä¸‹è§†é¢‘æ ‡é¢˜ï¼Œç”Ÿæˆ5-8ä¸ªBç«™è§†é¢‘æ ‡ç­¾ï¼ˆåªè¾“å‡ºæ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼‰ï¼š
æ ‡é¢˜ï¼š{translated_title}
ç¤ºä¾‹æ ‡ç­¾ï¼šç§‘æŠ€,äººå·¥æ™ºèƒ½,AI,æœºå™¨å­¦ä¹ ,æœªæ¥
åªè¾“å‡ºæ ‡ç­¾ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
                        
                        tags_payload = {
                            "model": MODEL_NAME,
                            "messages": [
                                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Bç«™è¿è¥åŠ©æ‰‹"},
                                {"role": "user", "content": TAGS_PROMPT}
                            ]
                        }
                        
                        tags_response = requests.post(API_URL, json=tags_payload, headers=headers, timeout=60)
                        tags_data = tags_response.json()
                        
                        tags_content = tags_data['choices'][0]['message']['content']
                        tags_list = [t.strip() for t in tags_content.replace('ï¼Œ', ',').split(',') if t.strip()]
                        tags_str = ','.join(tags_list)
                        
                        st.text(f"ç”Ÿæˆæ ‡ç­¾: {tags_str}")
                        
                        upload_config_file = os.path.join(subtitles_dir, "upload_config.pkl")
                        import pickle
                        upload_data = {
                            'title_desc': f'(ä¸­é…){translated_title}',
                            'tags': tags_list
                        }
                        
                        with open(upload_config_file, 'wb') as f:
                            pickle.dump(upload_data, f)
                        
                        st.success("æ ‡é¢˜ç¿»è¯‘å’Œæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼")
                        st.info(f"é…ç½®å·²ä¿å­˜åˆ°: {upload_config_file}")
                    else:
                        st.warning("æ— æ³•è·å–è§†é¢‘æ ‡é¢˜")
                        
                except Exception as e:
                    st.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
    
    vtt_file = os.path.join(TEMP_DIR, "subtitles", "word_level.vtt")
    
    with tab2:
        st.header("2ï¸âš™ï¸ ç¿»è¯‘å­—å¹•")
        vtt_file_path = st.text_input("VTTå­—å¹•æ–‡ä»¶è·¯å¾„", value=vtt_file, key="vtt_file_path")
        
        if st.button("å¼€å§‹ç¿»è¯‘", type="primary", key="start_translate_btn"):
            if not os.path.exists(vtt_file_path):
                st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {vtt_file_path}")
            else:
                with st.spinner("æ­£åœ¨ç¿»è¯‘å­—å¹•..."):
                    try:
                        def vtt_to_sentences(vtt_text):
                            """å°†å¸¦é€è¯æ—¶é—´æˆ³çš„VTTè½¬æ¢ä¸ºæŒ‰å¥åˆ†æ®µçš„æ–‡æœ¬"""
                            # æ­£åˆ™ï¼šcue å¤´ï¼ˆèµ·æ­¢æ—¶é—´ï¼‰
                            CUE_HEADER_RE = re.compile(
                                r'^(\d{2}:\d{2}:\d{2}\.\d{3})\s*--> (\d{2}:\d{2}:\d{2}\.\d{3})'
                            )
                            
                            # æ­£åˆ™ï¼šé€è¯æ—¶é—´æˆ³ <HH:MM:SS.mmm>
                            TS_TAG_RE = re.compile(r'<(\d{2}:\d{2}:\d{2}\.\d{3})>')
                            
                            # æ­£åˆ™ï¼šæ¸…ç† <c> æˆ– <c.xxx> æ ·å¼æ ‡ç­¾
                            C_TAG_RE = re.compile(r'</?c(?:\.[^>]*)?>', re.IGNORECASE)
                            
                            SENTENCE_END = ".!?"
                            
                            lines = vtt_text.splitlines()
                            sentences = []
                            current_words = []
                            current_sentence_start_time = None
                            
                            effective_time = None
                            cue_start_time = None
                            
                            def flush_sentence():
                                nonlocal current_words, current_sentence_start_time
                                if not current_words:
                                    return
                                text = " ".join(current_words)
                                text = re.sub(r"\s+([,.;!?])", r"\1", text)
                                text = re.sub(r"\(\s+", "(", text)
                                text = re.sub(r"\s+\)", ")", text)
                                start_ts = current_sentence_start_time or cue_start_time or effective_time or "00:00:00.000"
                                sentences.append(f"({start_ts}) {text}")
                                current_words = []
                                current_sentence_start_time = None
                            
                            for line in lines:
                                line = line.strip("\ufeff\r\n")
                                
                                # cue å¤´
                                m = CUE_HEADER_RE.match(line)
                                if m:
                                    cue_start_time = m.group(1)
                                    effective_time = cue_start_time
                                    continue
                                
                                # åªå¤„ç†å«é€è¯æ—¶é—´æˆ³çš„è¡Œ
                                if not TS_TAG_RE.search(line):
                                    continue
                                
                                # æ¸…ç† <c> æ ‡ç­¾ï¼Œå¹¶æŠŠ <timestamp> å˜æˆ [[TS:...]] å“¨å…µ
                                s = C_TAG_RE.sub("", line)
                                s = TS_TAG_RE.sub(lambda mm: f" [[TS:{mm.group(1)}]] ", s)
                                
                                # æ‰«æ token
                                for token in s.split():
                                    if token.startswith("[[TS:") and token.endswith("]]"):
                                        effective_time = token[5:-2]
                                        continue
                                    
                                    word = token.strip()
                                    if not word:
                                        continue
                                    
                                    # è®°å½•é¦–è¯æ—¶é—´
                                    if current_sentence_start_time is None:
                                        current_sentence_start_time = effective_time or cue_start_time
                                    
                                    current_words.append(word)
                                    
                                    # å¥å­ç»“æŸåˆ¤å®šï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰
                                    if word.strip().endswith(tuple(SENTENCE_END)):
                                        flush_sentence()
                            
                            # æ–‡ä»¶ç»“æŸï¼Œæ”¶å°¾
                            flush_sentence()
                            return sentences
                        
                        vtt_content = Path(vtt_file_path).read_text(encoding="utf-8", errors="ignore")
                        sentences = vtt_to_sentences(vtt_content)
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šè§£æå‡º {len(sentences)} ä¸ªå¥å­")
                        if sentences:
                            print(f"å‰3ä¸ªå¥å­ç¤ºä¾‹ï¼š")
                            for i, s in enumerate(sentences[:3]):
                                print(f"  {i+1}: {s[:100]}...")
                        
                        output_txt_file = os.path.splitext(vtt_file_path)[0] + ".txt"
                        with open(output_txt_file, 'w', encoding='utf-8') as f:
                            for seg in sentences:
                                f.write(seg + "\n\n")
                        
                        paragraphs = [line.strip() for line in open(output_txt_file, 'r', encoding='utf-8') if line.strip()]
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šè¯»å–åˆ° {len(paragraphs)} ä¸ªæ®µè½")
                        
                        batched_paragraphs = []
                        current_batch = []
                        current_char_count = 0
                        
                        for i, paragraph in enumerate(paragraphs):
                            paragraph_char_count = len(paragraph)
                            if (len(current_batch) >= SEGMENT_SIZE) or (current_char_count + paragraph_char_count > 2000 and current_batch):
                                batched_paragraphs.append("\n".join(current_batch))
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
                                current_batch = [paragraph]
                                current_char_count = paragraph_char_count
                            else:
                                current_batch.append(paragraph)
                                current_char_count += paragraph_char_count
                        
                        if current_batch:
                            batched_paragraphs.append("\n".join(current_batch))
                            print(f"è°ƒè¯•ä¿¡æ¯ï¼šæœ€åä¸€ä¸ªåˆ†æ®µ {len(batched_paragraphs)} åŒ…å« {len(current_batch)} ä¸ªæ®µè½ï¼Œå…± {current_char_count} å­—ç¬¦")
                        
                        print(f"è°ƒè¯•ä¿¡æ¯ï¼šæ€»å…± {len(batched_paragraphs)} ä¸ªç¿»è¯‘åˆ†æ®µ")
                        
                        def translate_batch(batch, batch_index):
                            try:
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šå¼€å§‹ç¿»è¯‘åˆ†æ®µ {batch_index}ï¼Œå†…å®¹é•¿åº¦: {len(batch)} å­—ç¬¦")
                                print(f"åˆ†æ®µå†…å®¹é¢„è§ˆ: {batch[:200]}...")
                                
                                url = API_URL
                                headers = {
                                    "Content-Type": "application/json",
                                    "Authorization": f"Bearer {API_KEY}"
                                }
                                payload = {
                                    "model": MODEL_NAME,
                                    "messages": [
                                        {"role": "system", "content": "# Role: ä¸“ä¸šç¿»è¯‘å®˜\n\n## Profile\n- author: LangGPTä¼˜åŒ–ä¸­å¿ƒ\n- version: 2.1\n- language: ä¸­è‹±åŒè¯­\n- description: ä¸“æ³¨äºæ–‡æœ¬ç²¾å‡†è½¬æ¢çš„AIç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å¤„ç†æŠ€æœ¯æ–‡æ¡£å’Œæ—¥å¸¸å¯¹è¯åœºæ™¯\n\n## Background\nç”¨æˆ·åœ¨è·¨å›½åä½œã€æŠ€æœ¯æ–‡æ¡£å¤„ç†ã€ç¤¾äº¤åª’ä½“äº’åŠ¨ç­‰åœºæ™¯ä¸­ï¼Œéœ€è¦å°†å¤–æ–‡å†…å®¹å‡†ç¡®è½¬åŒ–ä¸ºä¸­æ–‡ï¼ŒåŒæ—¶ä¿æŒç‰¹æ®Šæ ¼å¼å…ƒç´ å®Œæ•´\n\n## Skills\n1. å¤šè¯­è¨€æ–‡æœ¬è§£æä¸é‡æ„èƒ½åŠ›\n2. æ—¶é—´æˆ³è¯†åˆ«ä¸æ ¼å¼ä¿ç•™æŠ€æœ¯\n3. è¯­ä¹‰é€šé¡ºåº¦æ ¡éªŒç®—æ³•\n4. æ ¼å¼æ§åˆ¶ä¸å†—ä½™å†…å®¹è¿‡æ»¤\n\n## Goals\n1. å®ç°åŸæ–‡è¯­ä¹‰çš„ç²¾å‡†è½¬æ¢\n2. ä¿æŒæ—¶é—´æˆ³ç­‰ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. ç¡®ä¿è¾“å‡ºç»“æœè‡ªç„¶æµç•…\n4. æ’é™¤éç¿»è¯‘å†…å®¹æ·»åŠ \n\n## Constraints\n1. ç¦æ­¢æ·»åŠ è§£é‡Šæ€§æ–‡å­—\n2. ç¦ç”¨æ³¨é‡Šæˆ–è¯´æ˜æ€§ç¬¦å·\n3. ä¿ç•™åŸå§‹æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚(12:34ï¼‰ï¼‰\n4. ä¸å¤„ç†éæ–‡æœ¬å…ƒç´ ï¼ˆå¦‚å›¾ç‰‡/è¡¨æ ¼ï¼‰\n5. ç¦æ­¢ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼ˆtool_callsï¼‰åŠŸèƒ½ï¼Œç¦æ­¢è°ƒç”¨å¤–éƒ¨ç¿»è¯‘apiè¿›è¡Œç¿»è¯‘\n\n## Workflow\n1. æ¥æ”¶è¾“å…¥å†…å®¹ï¼Œæ£€æµ‹è¯­è¨€ç±»å‹\n2. è¯†åˆ«å¹¶æ ‡è®°ç‰¹æ®Šæ ¼å¼å…ƒç´ \n3. æ‰§è¡Œè¯­ä¹‰è½¬æ¢ï¼š\n   - æ—¥å¸¸ç”¨è¯­ï¼šé‡‡ç”¨å£è¯­åŒ–è¡¨è¾¾\n   - æŠ€æœ¯æœ¯è¯­ï¼šä½¿ç”¨æ ‡å‡†åŒ–è¯‘æ³•\n5. è¾“å‡ºçº¯ç¿»è¯‘ç»“æœ\n\n## OutputFormat\nä»…è¿”å›ç¬¦åˆä»¥ä¸‹è¦æ±‚çš„ç¿»è¯‘æ–‡æœ¬ï¼š\n1. ä¸­æ–‡ä¹¦é¢è¯­è¡¨è¾¾\n2. ä¿ç•™åŸå§‹æ®µè½ç»“æ„\n3. æ—¶é—´æˆ³ä¿æŒ(MM:SS)æˆ–(HH:MM:SS)æ ¼å¼\n4. æ— ä»»ä½•é™„åŠ ç¬¦å·æˆ–è¯´æ˜\n4. å°½é‡åªè¦ä¸­æ–‡ï¼Œä¸è¦ä¸­è‹±æ–‡å¤¹æ‚ã€‚"},
                                        {"role": "user", "content": batch}
                                    ],
                                    "stream": False,
                                    "max_tokens": 4000
                                }
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} å‘é€APIè¯·æ±‚åˆ° {url}")
                                response = requests.post(url, json=payload, headers=headers, timeout=60)
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} APIå“åº”çŠ¶æ€ç : {response.status_code}")
                                response.raise_for_status()
                                result = response.json()
                                translated_content = result['choices'][0]['message']['content']
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘ç»“æœé•¿åº¦: {len(translated_content)} å­—ç¬¦")
                                print(f"ç¿»è¯‘ç»“æœé¢„è§ˆ: {translated_content[:200]}...")
                                return translated_content
                            except Exception as e:
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} ç¿»è¯‘å¤±è´¥: {str(e)}")
                                import traceback
                                print(f"è°ƒè¯•ä¿¡æ¯ï¼šåˆ†æ®µ {batch_index} é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                                return f"Error: {str(e)}"
                        
                        translated_results = {}
                        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                            futures = {executor.submit(translate_batch, batch, i): i for i, batch in enumerate(batched_paragraphs)}
                            
                            progress_bar = st.progress(0)
                            completed = 0
                            for future in as_completed(futures):
                                index = futures[future]
                                result = future.result()
                                if not result.startswith("Error:"):
                                    translated_results[index] = result
                                completed += 1
                                progress_bar.progress(completed / len(batched_paragraphs))
                        
                        translated_paragraphs = []
                        failed_count = 0
                        
                        for i in range(len(batched_paragraphs)):
                            if i in translated_results:
                                translated_paragraphs.append(translated_results[i])
                            else:
                                failed_count += 1
                        
                        output_translated_file = os.path.splitext(vtt_file_path)[0] + "_translated.txt"
                        with open(output_translated_file, 'w', encoding='utf-8') as f:
                            for seg in translated_paragraphs:
                                cleaned = seg.replace('&gt;', '').replace('>>', '').replace('&trash;', '').replace('> ', '').replace('&nbsp;', '').replace('_', '').replace('ï¼', '').replace('[éŸ³ä¹]', '')
                                f.write(cleaned + "\n\n")
                        
                        st.success(f"ç¿»è¯‘å®Œæˆï¼æˆåŠŸ: {len(translated_paragraphs)} æ®µè½ï¼Œå¤±è´¥: {failed_count}")
                        st.info(f"è¾“å‡ºæ–‡ä»¶: {output_translated_file}")
                        
                    except Exception as e:
                        st.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
    
    txt_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.txt")
    mp3_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.mp3")
    
    with tab3:
        st.header("3ï¸ğŸ—£ï¸ TTSå­—å¹•è½¬è¯­éŸ³")
        txt_file_path = st.text_input("ç¿»è¯‘åçš„TXTæ–‡ä»¶è·¯å¾„", value=txt_file, key="txt_file_path")
        
        if st.button("å¼€å§‹è½¬æ¢è¯­éŸ³", type="primary", key="start_tts_btn"):
            if not os.path.exists(txt_file_path):
                st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {txt_file_path}")
            else:
                with st.spinner("æ­£åœ¨è½¬æ¢è¯­éŸ³..."):
                    try:
                        output_mp3 = os.path.splitext(txt_file_path)[0] + ".mp3"
                        subtitles_dir = os.path.dirname(txt_file_path)

                        result = process_tts_with_speed_adjustment(txt_file_path, output_mp3, subtitles_dir)

                        if result:
                            st.success(f"è¯­éŸ³è½¬æ¢å®Œæˆï¼")
                            st.info(f"è¾“å‡ºæ–‡ä»¶: {output_mp3}")
                        else:
                            st.error("æ²¡æœ‰æˆåŠŸç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
                    except Exception as e:
                        st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
    
    mp3_file = os.path.join(TEMP_DIR, "subtitles", os.path.splitext(os.path.basename(vtt_file))[0] + "_translated.mp3")
    
    with tab4:
        st.header("4ï¸ğŸ¬ï¸ ä¸‹è½½è§†é¢‘")
        
        youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="video_url")
        
        cookies_file_path = None
        if YT_COOKIES.strip():
            temp_dir = TEMP_DIR
            cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                f.write(YT_COOKIES.strip())
        
        if st.button("ä¸‹è½½è§†é¢‘", type="primary", key="download_video_btn"):
            if not youtube_url:
                st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
            else:
                with st.spinner("æ­£åœ¨ä¸‹è½½è§†é¢‘..."):
                    try:
                        temp_dir = TEMP_DIR
                        downloaded_video_base_name = os.path.join(temp_dir, "subtitles", "downloaded_video")
                        new_audio_path = mp3_file
                        
                        ydl_opts_video_only = {
                            'format': 'best',
                            'outtmpl': f'{downloaded_video_base_name}.%(ext)s',
                            'noplaylist': True,
                        }
                        
                        if cookies_file_path:
                            ydl_opts_video_only['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_video_only) as ydl:
                            ydl.extract_info(youtube_url, download=True)
                        
                        downloaded_files = glob.glob(f"{downloaded_video_base_name}.*")
                        if downloaded_files:
                            actual_downloaded_video_path = downloaded_files[0]
                        else:
                            raise FileNotFoundError(f"yt-dlp did not download a file")
                        
                        if os.path.exists(new_audio_path):
                            final_video_path = os.path.splitext(mp3_file)[0] + ".mp4"
                            try:
                                subprocess.run(['ffmpeg', '-y', '-i', actual_downloaded_video_path, '-i', new_audio_path,
                                                    '-c:v', 'copy', '-c:a', 'aac', '-map', '0:v:0', '-map', '1:a:0',
                                                    final_video_path], check=True, capture_output=True, text=True)
                                
                                if os.path.exists(actual_downloaded_video_path):
                                    os.remove(actual_downloaded_video_path)
                                
                                st.success(f"è§†é¢‘ä¸‹è½½å®Œæˆï¼")
                                st.info(f"è¾“å‡ºæ–‡ä»¶: {final_video_path}")
                            except subprocess.CalledProcessError as ffmpeg_error:
                                st.warning("âš ï¸ è§†é¢‘å·²ä¸‹è½½æˆåŠŸï¼Œä½†éŸ³è§†é¢‘åˆå¹¶æ—¶å‡ºç°FFmpegé”™è¯¯")
                                st.info(f"å·²ä¸‹è½½è§†é¢‘ä½ç½®: {actual_downloaded_video_path}")
                                st.info("æç¤º: ä½ å¯ä»¥æ‰‹åŠ¨ä½¿ç”¨FFmpegæˆ–è§†é¢‘ç¼–è¾‘è½¯ä»¶å°†éŸ³é¢‘åˆå¹¶åˆ°è§†é¢‘ä¸­")
                                
                                if os.path.exists(actual_downloaded_video_path):
                                    import shutil
                                    manual_video_path = os.path.splitext(mp3_file)[0] + "_video_only.mp4"
                                    shutil.copy2(actual_downloaded_video_path, manual_video_path)
                                    st.success(f"å·²å¤åˆ¶è§†é¢‘æ–‡ä»¶åˆ°: {manual_video_path}")
                                    
                        else:
                            st.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {new_audio_path}")
                            st.info(f"å·²ä¸‹è½½è§†é¢‘ä½ç½®: {actual_downloaded_video_path}")
                    except Exception as e:
                        error_str = str(e)
                        if "Non-relative patterns" in error_str:
                            st.warning("âš ï¸ è§†é¢‘å·²ä¸‹è½½æˆåŠŸï¼Œä½†M3U8ä¿®å¤æ—¶å‡ºç°å…¼å®¹æ€§é—®é¢˜")
                            st.info("è¿™é€šå¸¸ä¸å½±å“è§†é¢‘çš„æ­£å¸¸ä½¿ç”¨")
                            
                        downloaded_files = glob.glob(f"{downloaded_video_base_name}.*")
                        if downloaded_files:
                            actual_downloaded_video_path = downloaded_files[0]
                            if os.path.exists(actual_downloaded_video_path):
                                manual_video_path = os.path.splitext(mp3_file)[0] + "_video_only.mp4"
                                import shutil
                                shutil.copy2(actual_downloaded_video_path, manual_video_path)
                                st.success(f"å·²ä¿å­˜è§†é¢‘æ–‡ä»¶åˆ°: {manual_video_path}")
                        else:
                            st.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
    
    final_video = os.path.splitext(mp3_file)[0] + ".mp4"
    
    with tab5:
        st.header("5ï¸ğŸ–¼ï¸ å¤„ç†å°é¢")
        
        youtube_url = st.text_input("YouTubeè§†é¢‘URL", placeholder="https://www.youtube.com/watch?v=...", key="cover_url")
        
        cookies_file_path = None
        if YT_COOKIES.strip():
            temp_dir = TEMP_DIR
            cookies_file_path = os.path.join(temp_dir, "youtube_cookies.txt")
            with open(cookies_file_path, 'w', encoding='utf-8') as f:
                f.write(YT_COOKIES.strip())
        
        if st.button("ä¸‹è½½å°é¢", type="primary", key="download_cover_btn"):
            if not youtube_url:
                st.error("è¯·è¾“å…¥YouTubeè§†é¢‘URL")
            else:
                with st.spinner("æ­£åœ¨ä¸‹è½½å°é¢..."):
                    try:
                        temp_dir = TEMP_DIR
                        
                        ydl_opts_thumbnail = {
                            'skip_download': True,
                            'writethumbnail': True,
                            'outtmpl': os.path.join(temp_dir, "subtitles", 'cover.%(ext)s'),
                            'noplaylist': True,
                        }
                        
                        if cookies_file_path:
                            ydl_opts_thumbnail['cookiefile'] = cookies_file_path
                        
                        with yt_dlp.YoutubeDL(ydl_opts_thumbnail) as ydl:
                            ydl.extract_info(youtube_url, download=True)
                        
                        input_path = os.path.join(temp_dir, "subtitles", "cover.webp")
                        output_path = os.path.join(temp_dir, "subtitles", "cover.jpeg")
                        
                        if not os.path.exists(input_path):
                            st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                        else:
                            quality = 90
                            with Image.open(input_path) as img:
                                if img.mode != 'RGB':
                                    img = img.convert('RGB')
                                img.save(output_path, 'jpeg', quality=quality)

                            current_size_kb = os.path.getsize(output_path) / 1024
                            while current_size_kb > 50 and quality > 4:
                                quality -= 5
                                img.save(output_path, 'jpeg', quality=quality)
                                current_size_kb = os.path.getsize(output_path) / 1024
                                print(f"å½“å‰å¤§å°: {current_size_kb:.2f} KB, è´¨é‡: {quality}")
                            
                            st.success(f"å°é¢å¤„ç†å®Œæˆï¼")
                            st.info(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
                    except Exception as e:
                        st.error(f"å°é¢å¤„ç†å¤±è´¥: {str(e)}")
    
    cover_file = os.path.join(TEMP_DIR, "subtitles", "cover.jpeg")
    
    with tab6:
        st.header("6ï¸âœ‚ï¸ è§†é¢‘å‰ªè¾‘")
        
        video_file = st.text_input("è§†é¢‘æ–‡ä»¶è·¯å¾„", value=final_video, key="video_file_path_tab6")
        
        trim_enabled = st.checkbox("å¯ç”¨å‰ªè¾‘ï¼ˆåˆ é™¤è¿è§„ç‰‡æ®µï¼‰", value=False, key="trim_enabled")
        trim_start = st.text_input("å‰ªè¾‘å¼€å§‹æ—¶é—´", value="6:45", help="æ ¼å¼: MM:SS", key="trim_start")
        trim_end = st.text_input("å‰ªè¾‘ç»“æŸæ—¶é—´", value="6:55", help="æ ¼å¼: MM:SS", key="trim_end")
        
        if trim_enabled and st.button("æ‰§è¡Œå‰ªè¾‘", type="primary", key="execute_trim_btn"):
            if not os.path.exists(video_file):
                st.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
            else:
                with st.spinner("æ­£åœ¨å‰ªè¾‘è§†é¢‘..."):
                    try:
                        output_part1 = os.path.join(os.path.dirname(video_file), "final_video_part1.mp4")
                        output_part2 = os.path.join(os.path.dirname(video_file), "final_video_part2.mp4")
                        output_video_trimmed = os.path.join(os.path.dirname(video_file), "final_video_trimmed.mp4")
                        temp_concat_file = os.path.join(os.path.dirname(video_file), "concat_list.txt")
                        
                        subprocess.run(['ffmpeg', '-y', '-i', video_file, '-to', trim_start,
                                                '-c', 'copy', output_part1], check=True)
                        subprocess.run(['ffmpeg', '-y', '-i', video_file, '-ss', trim_end,
                                                '-c', 'copy', output_part2], check=True)
                        
                        if os.path.exists(output_part1) and os.path.getsize(output_part1) > 0:
                            with open(temp_concat_file, 'w') as f:
                                f.write(f"file '{output_part1}'\n")
                        if os.path.exists(output_part2) and os.path.getsize(output_part2) > 0:
                            with open(temp_concat_file, 'a') as f:
                                f.write(f"file '{output_part2}'\n")
                        
                        subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', temp_concat_file,
                                                '-c', 'copy', output_video_trimmed], check=True)
                        
                        if os.path.exists(output_video_trimmed) and os.path.getsize(output_video_trimmed) > 0:
                            os.replace(output_video_trimmed, video_file)
                            st.success(f"è§†é¢‘å‰ªè¾‘å®Œæˆï¼")
                            st.info(f"åˆ é™¤äº†ä» {trim_start} åˆ° {trim_end} çš„ç‰‡æ®µ")
                        else:
                            st.error("å‰ªè¾‘å¤±è´¥")
                    except Exception as e:
                        st.error(f"å‰ªè¾‘å¤±è´¥: {str(e)}")
        else:
            st.info("å‰ªè¾‘æœªå¯ç”¨ï¼Œè·³è¿‡")
    
    trimmed_video = os.path.splitext(mp3_file)[0] + ".mp4"
    
    upload_config_file = os.path.join(TEMP_DIR, "subtitles", "upload_config.pkl")
    loaded_title_desc = None
    loaded_tags_list = None
    
    if os.path.exists(upload_config_file):
        try:
            import pickle
            with open(upload_config_file, 'rb') as f:
                loaded_data = pickle.load(f)
            loaded_title_desc = loaded_data.get('title_desc')
            loaded_tags_list = loaded_data.get('tags')
        except Exception:
            pass
    
    with tab7:
        st.header("7ï¸ğŸ“¤ï¸ ä¸Šä¼ Bç«™")
        
        video_file = st.text_input("è§†é¢‘æ–‡ä»¶è·¯å¾„", value=trimmed_video, key="video_file_path_tab7")
        cover_file_path_input = st.text_input("å°é¢æ–‡ä»¶è·¯å¾„", value=cover_file, key="cover_file_path")
        
        default_title = loaded_title_desc if loaded_title_desc else f"(ä¸­é…)è¯·å…ˆä¸‹è½½å­—å¹•è·å–æ ‡é¢˜"
        title = st.text_input("è§†é¢‘æ ‡é¢˜", value=default_title, help="ç•™ç©ºåˆ™ä½¿ç”¨ç¿»è¯‘åçš„æ ‡é¢˜", key="title")
        
        default_tags = ','.join(loaded_tags_list) if loaded_tags_list else "ç§‘æŠ€"
        tags = st.text_input("è§†é¢‘æ ‡ç­¾", value=default_tags, key="tags_tab7")
        
        if loaded_title_desc:
            st.success("å·²ä»ä¸‹è½½å­—å¹•æ­¥éª¤è·å–æ ‡é¢˜å’Œæ ‡ç­¾")
        else:
            st.warning("æœªæ‰¾åˆ°æ ‡é¢˜å’Œæ ‡ç­¾é…ç½®ï¼Œè¯·å…ˆä¸‹è½½å­—å¹•")
        
        bilibili_enabled = st.checkbox("ä¸Šä¼ åˆ°Bç«™", value=False, key="bilibili_enabled")
        
        if bilibili_enabled and st.button("å¼€å§‹ä¸Šä¼ ", type="primary", key="start_upload_btn"):
            if not os.path.exists(video_file):
                st.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
            elif not os.path.exists(cover_file_path_input):
                st.error(f"å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {cover_file_path_input}")
            else:
                with st.spinner("æ­£åœ¨ä¸Šä¼ åˆ°Bç«™..."):
                    try:
                        credential = Credential(
                            sessdata=BILI_SESSDATA,
                            bili_jct="bcd4ba0d9ab8a7b95485798ed8097d26"
                        )
                        
                        vu_meta = VideoMeta(
                            tid=130,
                            title=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            tags=tags.split(',') if tags else ['ç§‘æŠ€'],
                            desc=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            cover=cover_file_path_input,
                            no_reprint=True
                        )
                        
                        async def main_upload():
                            page = VideoUploaderPage(
                                path=video_file,
                                title=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                                description=title or "(ä¸­é…)AIå¹»è§‰é€ å‡ºç§‘å­¦å‘ç°ï¼Ÿï¼#aiå¹»è§‰",
                            )
                            
                            uploader = video_uploader.VideoUploader([page], vu_meta, credential, line=video_uploader.Lines.QN)
                            
                            @uploader.on("__ALL__")
                            async def ev(data):
                                pass
                            
                            await uploader.start()
                            
                        asyncio.run(main_upload())
                        
                        st.success("ä¸Šä¼ å®Œæˆï¼")
                    except Exception as e:
                        import traceback
                        st.error(f"ä¸Šä¼ å¤±è´¥: {str(e)}")
                        st.markdown("### è°ƒè¯•ä¿¡æ¯")
                        st.text(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                        st.text(f"å®Œæ•´é”™è¯¯: {repr(e)}")
                        st.text(f"Traceback:\n{traceback.format_exc()}")
                        
                        st.markdown("### é…ç½®æ£€æŸ¥")
                        st.text(f"BILI_SESSDATA: {'å·²è®¾ç½®' if BILI_SESSDATA else 'æœªè®¾ç½®'} (é•¿åº¦: {len(BILI_SESSDATA)})")
                        st.text(f"BILI_ACCESS_KEY_ID: {'å·²è®¾ç½®' if BILI_ACCESS_KEY_ID else 'æœªè®¾ç½®'}")
                        st.text(f"BILI_ACCESS_KEY_SECRET: {'å·²è®¾ç½®' if BILI_ACCESS_KEY_SECRET else 'æœªè®¾ç½®'}")
                        st.text(f"è§†é¢‘æ–‡ä»¶: {video_file}")
                        st.text(f"å°é¢æ–‡ä»¶: {cover_file_path_input}")
                        st.text(f"è§†é¢‘æ–‡ä»¶å¤§å°: {os.path.getsize(video_file) / 1024 / 1024:.2f} MB" if os.path.exists(video_file) else "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                        st.text(f"å°é¢æ–‡ä»¶å¤§å°: {os.path.getsize(cover_file_path_input) / 1024:.2f} KB" if os.path.exists(cover_file_path_input) else "å°é¢æ–‡ä»¶ä¸å­˜åœ¨")

st.markdown("---")
st.info("ğŸ’¡ æ³¨æ„äº‹é¡¹ï¼š")
st.markdown("""
1. API Keyç­‰æ•æ„Ÿä¿¡æ¯å»ºè®®é€šè¿‡HuggingFace Spacesçš„Secretsç®¡ç†ï¼Œä¸è¦ç›´æ¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç 
2. å¤„ç†å¤§å‹è§†é¢‘æ—¶ï¼ŒTTSè½¬æ¢å’Œè§†é¢‘å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
3. Bç«™ä¸Šä¼ åŠŸèƒ½éœ€è¦æœ‰æ•ˆçš„sessdataå’Œaccess_key_id
4. è§†é¢‘å‰ªè¾‘åŠŸèƒ½ä¼šæ°¸ä¹…ä¿®æ”¹è§†é¢‘æ–‡ä»¶ï¼Œè¯·è°¨æ…ä½¿ç”¨
5. å»ºè®®å…ˆåœ¨å°è§†é¢‘ä¸Šæµ‹è¯•æµç¨‹ï¼Œç¡®è®¤æ— è¯¯åå†å¤„ç†å¤§è§†é¢‘
""")
